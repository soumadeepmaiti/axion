{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Multi-Input Hybrid Deep Learning Crypto Trading System\n",
    "## Complete Technical Documentation & Testing Notebook\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [System Overview & Architecture](#1-system-overview)\n",
    "2. [Environment Setup](#2-environment-setup)\n",
    "3. [Data Acquisition Pipeline](#3-data-acquisition)\n",
    "4. [Feature Engineering](#4-feature-engineering)\n",
    "5. [Technical Indicators](#5-technical-indicators)\n",
    "6. [Model Architectures](#6-model-architectures)\n",
    "7. [Single Asset Training & Prediction](#7-single-asset-training)\n",
    "8. [Multi-Asset Portfolio Optimization](#8-portfolio-optimization)\n",
    "9. [Correlation & Risk Analysis](#9-correlation-analysis)\n",
    "10. [Deep Learning Portfolio Strategy](#10-deep-learning-portfolio)\n",
    "11. [Reinforcement Learning Strategy](#11-rl-strategy)\n",
    "12. [Hybrid Ensemble Strategy](#12-hybrid-strategy)\n",
    "13. [Model Persistence](#13-model-persistence)\n",
    "14. [Backtesting](#14-backtesting)\n",
    "15. [AI Advisor Integration](#15-ai-advisor)\n",
    "16. [Complete Workflow Demo](#16-complete-workflow)\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Crypto Trading System  \n",
    "**Version:** 2.0  \n",
    "**Last Updated:** February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. System Overview & Architecture <a id='1-system-overview'></a>\n",
    "\n",
    "## System Goals\n",
    "\n",
    "1. **Price Prediction** - Predict whether asset price will go UP or DOWN\n",
    "2. **Portfolio Allocation** - Determine optimal capital allocation across multiple assets\n",
    "3. **Risk Management** - Minimize losses while maximizing returns\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    FRONTEND (React.js)                          â”‚\n",
    "â”‚  Dashboard â”‚ Training â”‚ Portfolio â”‚ Backtesting â”‚ AI Advisor    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    BACKEND (FastAPI)                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Data Pipeline    â”‚  Training Service  â”‚  Portfolio Optimizer   â”‚\n",
    "â”‚  - CCXT Exchange  â”‚  - 11+ Models      â”‚  - Traditional+ML      â”‚\n",
    "â”‚  - Multi-Asset    â”‚  - Walk-Forward    â”‚  - Deep Learning       â”‚\n",
    "â”‚  - Any Date Range â”‚  - Hyperparameter  â”‚  - RL Agent (PPO)      â”‚\n",
    "â”‚                   â”‚                    â”‚  - Hybrid Ensemble     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ML Models (TensorFlow/Keras)          â”‚  LLM Service           â”‚\n",
    "â”‚  - LSTM, GRU, Transformer              â”‚  - OpenAI GPT          â”‚\n",
    "â”‚  - CNN-LSTM, Attention                 â”‚  - Claude              â”‚\n",
    "â”‚  - TCN-GNN-LSTM Hybrid                 â”‚  - Gemini              â”‚\n",
    "â”‚  - RL (DQN, PPO)                       â”‚                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    DATA SOURCES                                  â”‚\n",
    "â”‚  Binance â”‚ OKX â”‚ KuCoin â”‚ Bybit â”‚ Kraken â”‚ Coinbase             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Environment Setup <a id='2-environment-setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# API Configuration\n",
    "API_BASE_URL = \"https://work-1-oqzcuohwva-ue.a.run.app/api\"\n",
    "\n",
    "# Helper functions\n",
    "def api_get(endpoint, params=None):\n",
    "    \"\"\"Make GET request to API\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}{endpoint}\", params=params, timeout=60)\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def api_post(endpoint, data):\n",
    "    \"\"\"Make POST request to API\"\"\"\n",
    "    try:\n",
    "        response = requests.post(f\"{API_BASE_URL}{endpoint}\", json=data, timeout=120)\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def print_header(title):\n",
    "    \"\"\"Print formatted header\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"  {title}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "def print_success(msg):\n",
    "    print(f\"âœ… {msg}\")\n",
    "\n",
    "def print_info(msg):\n",
    "    print(f\"â„¹ï¸  {msg}\")\n",
    "\n",
    "def print_warning(msg):\n",
    "    print(f\"âš ï¸  {msg}\")\n",
    "\n",
    "print_header(\"ENVIRONMENT SETUP COMPLETE\")\n",
    "print_success(f\"API URL: {API_BASE_URL}\")\n",
    "print_success(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify API connection\n",
    "print_header(\"API CONNECTION TEST\")\n",
    "\n",
    "# Test endpoint\n",
    "health = api_get(\"/dashboard/stats\")\n",
    "\n",
    "if \"error\" not in health:\n",
    "    print_success(\"API connection successful!\")\n",
    "    print(f\"\\nğŸ“Š System Statistics:\")\n",
    "    print(f\"   â€¢ Has Advanced Model: {health.get('has_advanced_model', False)}\")\n",
    "    print(f\"   â€¢ Total Predictions Made: {health.get('total_predictions', 0)}\")\n",
    "    print(f\"   â€¢ Total Training Runs: {health.get('total_training_runs', 0)}\")\n",
    "else:\n",
    "    print_warning(f\"API connection failed: {health.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Data Acquisition Pipeline <a id='3-data-acquisition'></a>\n",
    "\n",
    "## Supported Exchanges\n",
    "- **Binance** (default) - Largest crypto exchange\n",
    "- **OKX** - Major derivatives exchange\n",
    "- **KuCoin, Bybit, Kraken, Coinbase** - Additional support\n",
    "\n",
    "## Data Types\n",
    "- **OHLCV** - Open, High, Low, Close, Volume\n",
    "- **Timeframes** - 1m, 5m, 15m, 1h, 4h, 1d, 1w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"DATA ACQUISITION - SINGLE ASSET\")\n",
    "\n",
    "# Fetch BTC/USDT data\n",
    "symbol = \"BTC/USDT\"\n",
    "timeframe = \"1h\"\n",
    "limit = 500\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Fetching {symbol} data...\")\n",
    "print(f\"   Timeframe: {timeframe}\")\n",
    "print(f\"   Limit: {limit} candles\")\n",
    "\n",
    "market_data = api_get(f\"/market-data?symbol={symbol}&timeframe={timeframe}&limit={limit}\")\n",
    "\n",
    "if market_data.get('data'):\n",
    "    df = pd.DataFrame(market_data['data'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    print_success(f\"Fetched {len(df)} candles\")\n",
    "    print(f\"\\nğŸ“… Date Range:\")\n",
    "    print(f\"   From: {df.index.min()}\")\n",
    "    print(f\"   To: {df.index.max()}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Price Statistics:\")\n",
    "    print(f\"   Current Price: ${df['close'].iloc[-1]:,.2f}\")\n",
    "    print(f\"   High: ${df['high'].max():,.2f}\")\n",
    "    print(f\"   Low: ${df['low'].min():,.2f}\")\n",
    "    print(f\"   Avg Volume: {df['volume'].mean():,.2f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¢ Sample Data (Last 5 candles):\")\n",
    "    display(df[['open', 'high', 'low', 'close', 'volume']].tail())\n",
    "else:\n",
    "    print_warning(\"Failed to fetch data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price data\n",
    "print_header(\"PRICE CHART VISUALIZATION\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Price chart\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df.index, df['close'], color='#00d4aa', linewidth=1.5, label='Close Price')\n",
    "ax1.fill_between(df.index, df['low'], df['high'], alpha=0.2, color='#00d4aa')\n",
    "ax1.set_title(f'{symbol} Price Chart ({timeframe})', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Price (USDT)', fontsize=12)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Volume chart\n",
    "ax2 = axes[1]\n",
    "colors = ['#00d4aa' if df['close'].iloc[i] >= df['open'].iloc[i] else '#ef4444' \n",
    "          for i in range(len(df))]\n",
    "ax2.bar(df.index, df['volume'], color=colors, alpha=0.7, width=0.03)\n",
    "ax2.set_ylabel('Volume', fontsize=12)\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print_success(\"Price chart generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"ARBITRARY DATE RANGE FETCHING\")\n",
    "\n",
    "print(\"\\nğŸ“… Testing long historical data fetch...\")\n",
    "print(\"   This feature allows fetching data from ANY date range (e.g., 2017 to today)\")\n",
    "\n",
    "# Preview data for 3-year range\n",
    "data_preview = api_post(\"/training/data-preview\", {\n",
    "    \"symbol\": \"BTC/USDT\",\n",
    "    \"timeframe\": \"1d\",\n",
    "    \"start_date\": \"2022-01-01T00:00:00Z\",\n",
    "    \"end_date\": \"2024-12-31T00:00:00Z\"\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ” Data Preview (3-year daily data):\")\n",
    "print(f\"   Symbol: {data_preview.get('symbol')}\")\n",
    "print(f\"   Timeframe: {data_preview.get('timeframe')}\")\n",
    "print(f\"   Start Date: {data_preview.get('start_date')}\")\n",
    "print(f\"   End Date: {data_preview.get('end_date')}\")\n",
    "print(f\"   Estimated Candles: {data_preview.get('estimated_candles'):,}\")\n",
    "print(f\"   Estimated Training Samples: {data_preview.get('estimated_training_samples'):,}\")\n",
    "print(f\"   Exchange: {data_preview.get('exchange')}\")\n",
    "\n",
    "if data_preview.get('size_warning'):\n",
    "    print_warning(f\"   {data_preview.get('size_warning')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Feature Engineering <a id='4-feature-engineering'></a>\n",
    "\n",
    "## Feature Categories\n",
    "\n",
    "1. **Price-based Features** - Returns, momentum, price ratios\n",
    "2. **Volume Features** - Volume changes, volume ratios\n",
    "3. **Technical Indicators** - RSI, MACD, Bollinger Bands, etc.\n",
    "4. **Volatility Features** - ATR, historical volatility\n",
    "5. **Market Regime** - Trend detection, regime classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"FEATURE ENGINEERING DEMONSTRATION\")\n",
    "\n",
    "# Calculate features locally to demonstrate\n",
    "feature_df = df.copy()\n",
    "\n",
    "print(\"\\nğŸ“Š Calculating Features...\\n\")\n",
    "\n",
    "# 1. Returns\n",
    "feature_df['return_1'] = feature_df['close'].pct_change(1)\n",
    "feature_df['return_5'] = feature_df['close'].pct_change(5)\n",
    "feature_df['return_10'] = feature_df['close'].pct_change(10)\n",
    "feature_df['return_20'] = feature_df['close'].pct_change(20)\n",
    "print_success(\"Returns (1, 5, 10, 20 periods)\")\n",
    "\n",
    "# 2. Moving Averages\n",
    "feature_df['sma_20'] = feature_df['close'].rolling(20).mean()\n",
    "feature_df['sma_50'] = feature_df['close'].rolling(50).mean()\n",
    "feature_df['price_sma20_ratio'] = feature_df['close'] / feature_df['sma_20']\n",
    "feature_df['price_sma50_ratio'] = feature_df['close'] / feature_df['sma_50']\n",
    "print_success(\"Moving Averages (SMA 20, 50)\")\n",
    "\n",
    "# 3. RSI\n",
    "delta = feature_df['close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "rs = gain / loss\n",
    "feature_df['rsi'] = 100 - (100 / (1 + rs))\n",
    "print_success(\"RSI (14 period)\")\n",
    "\n",
    "# 4. MACD\n",
    "ema_12 = feature_df['close'].ewm(span=12).mean()\n",
    "ema_26 = feature_df['close'].ewm(span=26).mean()\n",
    "feature_df['macd'] = ema_12 - ema_26\n",
    "feature_df['macd_signal'] = feature_df['macd'].ewm(span=9).mean()\n",
    "feature_df['macd_hist'] = feature_df['macd'] - feature_df['macd_signal']\n",
    "print_success(\"MACD (12, 26, 9)\")\n",
    "\n",
    "# 5. Bollinger Bands\n",
    "feature_df['bb_middle'] = feature_df['close'].rolling(20).mean()\n",
    "bb_std = feature_df['close'].rolling(20).std()\n",
    "feature_df['bb_upper'] = feature_df['bb_middle'] + (bb_std * 2)\n",
    "feature_df['bb_lower'] = feature_df['bb_middle'] - (bb_std * 2)\n",
    "feature_df['bb_width'] = (feature_df['bb_upper'] - feature_df['bb_lower']) / feature_df['bb_middle']\n",
    "feature_df['bb_percent'] = (feature_df['close'] - feature_df['bb_lower']) / (feature_df['bb_upper'] - feature_df['bb_lower'])\n",
    "print_success(\"Bollinger Bands (20, 2)\")\n",
    "\n",
    "# 6. Volatility\n",
    "feature_df['volatility_10'] = feature_df['return_1'].rolling(10).std()\n",
    "feature_df['volatility_20'] = feature_df['return_1'].rolling(20).std()\n",
    "print_success(\"Volatility (10, 20 period)\")\n",
    "\n",
    "# 7. Volume Features\n",
    "feature_df['volume_sma'] = feature_df['volume'].rolling(20).mean()\n",
    "feature_df['volume_ratio'] = feature_df['volume'] / feature_df['volume_sma']\n",
    "print_success(\"Volume Features\")\n",
    "\n",
    "# 8. ATR (Average True Range)\n",
    "high_low = feature_df['high'] - feature_df['low']\n",
    "high_close = abs(feature_df['high'] - feature_df['close'].shift())\n",
    "low_close = abs(feature_df['low'] - feature_df['close'].shift())\n",
    "tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "feature_df['atr'] = tr.rolling(14).mean()\n",
    "feature_df['atr_percent'] = feature_df['atr'] / feature_df['close']\n",
    "print_success(\"ATR (14 period)\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Total Features Created: {len([c for c in feature_df.columns if c not in df.columns])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature statistics\n",
    "print_header(\"FEATURE STATISTICS\")\n",
    "\n",
    "feature_cols = ['return_1', 'return_5', 'rsi', 'macd', 'bb_percent', \n",
    "                'volatility_10', 'volume_ratio', 'atr_percent']\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Summary Statistics:\")\n",
    "display(feature_df[feature_cols].describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key features\n",
    "print_header(\"FEATURE VISUALIZATION\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# RSI\n",
    "ax1 = axes[0]\n",
    "ax1.plot(feature_df.index[-100:], feature_df['rsi'].iloc[-100:], color='#00d4aa', linewidth=1.5)\n",
    "ax1.axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Overbought (70)')\n",
    "ax1.axhline(y=30, color='green', linestyle='--', alpha=0.7, label='Oversold (30)')\n",
    "ax1.set_title('RSI (Relative Strength Index)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('RSI')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MACD\n",
    "ax2 = axes[1]\n",
    "ax2.plot(feature_df.index[-100:], feature_df['macd'].iloc[-100:], color='#00d4aa', linewidth=1.5, label='MACD')\n",
    "ax2.plot(feature_df.index[-100:], feature_df['macd_signal'].iloc[-100:], color='#f59e0b', linewidth=1.5, label='Signal')\n",
    "ax2.bar(feature_df.index[-100:], feature_df['macd_hist'].iloc[-100:], color='#8b5cf6', alpha=0.5, label='Histogram')\n",
    "ax2.set_title('MACD (Moving Average Convergence Divergence)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('MACD')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Bollinger Bands %\n",
    "ax3 = axes[2]\n",
    "ax3.plot(feature_df.index[-100:], feature_df['bb_percent'].iloc[-100:], color='#00d4aa', linewidth=1.5)\n",
    "ax3.axhline(y=1, color='red', linestyle='--', alpha=0.7)\n",
    "ax3.axhline(y=0, color='green', linestyle='--', alpha=0.7)\n",
    "ax3.set_title('Bollinger Band %B', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('%B')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Volatility\n",
    "ax4 = axes[3]\n",
    "ax4.plot(feature_df.index[-100:], feature_df['volatility_10'].iloc[-100:] * 100, color='#ef4444', linewidth=1.5, label='10-period')\n",
    "ax4.plot(feature_df.index[-100:], feature_df['volatility_20'].iloc[-100:] * 100, color='#00d4aa', linewidth=1.5, label='20-period')\n",
    "ax4.set_title('Historical Volatility', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Volatility (%)')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print_success(\"Feature visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Technical Indicators <a id='5-technical-indicators'></a>\n",
    "\n",
    "## Complete List of Indicators Used\n",
    "\n",
    "| Category | Indicator | Description |\n",
    "|----------|-----------|-------------|\n",
    "| Trend | SMA (20, 50) | Simple Moving Average |\n",
    "| Trend | EMA (12, 26) | Exponential Moving Average |\n",
    "| Momentum | RSI (6, 14, 24) | Relative Strength Index |\n",
    "| Momentum | MACD | Moving Average Convergence Divergence |\n",
    "| Momentum | Stochastic | %K and %D oscillators |\n",
    "| Momentum | ROC | Rate of Change |\n",
    "| Volatility | Bollinger Bands | Price bands with std dev |\n",
    "| Volatility | ATR | Average True Range |\n",
    "| Volatility | Historical Vol | Rolling standard deviation |\n",
    "| Volume | Volume Ratio | Volume vs Moving Average |\n",
    "| Volume | MFI | Money Flow Index |\n",
    "| Trend Strength | ADX | Average Directional Index |\n",
    "| Trend Strength | DI+/DI- | Directional Indicators |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"COMPLETE TECHNICAL INDICATOR LIST\")\n",
    "\n",
    "# Get data info from training endpoint to see all features\n",
    "data_info = api_post(\"/training/data-info\", {\n",
    "    \"symbol\": \"BTC/USDT\",\n",
    "    \"timeframe\": \"1h\",\n",
    "    \"start_date\": None,\n",
    "    \"end_date\": None\n",
    "})\n",
    "\n",
    "if data_info.get('feature_names'):\n",
    "    features = data_info['feature_names']\n",
    "    print(f\"\\nğŸ“Š Total Features Available: {len(features)}\")\n",
    "    print(f\"\\nğŸ”¢ Feature List:\")\n",
    "    \n",
    "    # Group features by category\n",
    "    categories = {\n",
    "        'Price Ratios': [f for f in features if 'ratio' in f or 'price' in f],\n",
    "        'RSI': [f for f in features if 'rsi' in f],\n",
    "        'MACD': [f for f in features if 'macd' in f],\n",
    "        'Bollinger': [f for f in features if 'bb' in f],\n",
    "        'Volatility': [f for f in features if 'volatil' in f or 'atr' in f],\n",
    "        'Volume': [f for f in features if 'volume' in f or 'mfi' in f],\n",
    "        'Trend': [f for f in features if 'adx' in f or 'di_' in f],\n",
    "        'Returns': [f for f in features if 'return' in f],\n",
    "        'Stochastic': [f for f in features if 'stoch' in f],\n",
    "        'Other': [f for f in features if not any(x in f for x in ['ratio', 'rsi', 'macd', 'bb', 'volatil', 'atr', 'volume', 'mfi', 'adx', 'di_', 'return', 'stoch', 'price'])]\n",
    "    }\n",
    "    \n",
    "    for cat, feats in categories.items():\n",
    "        if feats:\n",
    "            print(f\"\\n   {cat}:\")\n",
    "            for f in feats:\n",
    "                print(f\"      â€¢ {f}\")\n",
    "else:\n",
    "    print_info(\"Feature list not available - showing calculated features\")\n",
    "    print(f\"\\nCalculated features: {list(feature_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Model Architectures <a id='6-model-architectures'></a>\n",
    "\n",
    "## Available Neural Network Architectures\n",
    "\n",
    "### 1. Recurrent Neural Networks\n",
    "- **LSTM** - Long Short-Term Memory\n",
    "- **GRU** - Gated Recurrent Unit\n",
    "- **Bi-LSTM** - Bidirectional LSTM\n",
    "\n",
    "### 2. Attention-Based Models\n",
    "- **Transformer** - Self-attention mechanism\n",
    "- **Attention GRU** - GRU with attention layer\n",
    "\n",
    "### 3. Hybrid Models\n",
    "- **CNN-LSTM** - Convolutional + LSTM\n",
    "- **TCN-GNN-LSTM** - Temporal Conv + Graph NN + LSTM\n",
    "\n",
    "### 4. Reinforcement Learning\n",
    "- **DQN** - Deep Q-Network\n",
    "- **PPO** - Proximal Policy Optimization\n",
    "\n",
    "### 5. Ensemble\n",
    "- **Multi-Model Ensemble** - Voting, Stacking, Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"MODEL ARCHITECTURES\")\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"LSTM\",\n",
    "        \"type\": \"Recurrent\",\n",
    "        \"description\": \"Long Short-Term Memory - Captures long-term dependencies in sequences\",\n",
    "        \"best_for\": \"Time series with long-term patterns\",\n",
    "        \"params\": \"~50K-200K\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GRU\",\n",
    "        \"type\": \"Recurrent\",\n",
    "        \"description\": \"Gated Recurrent Unit - Simpler than LSTM, faster training\",\n",
    "        \"best_for\": \"When training speed is important\",\n",
    "        \"params\": \"~40K-150K\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Bi-LSTM\",\n",
    "        \"type\": \"Recurrent\",\n",
    "        \"description\": \"Processes sequence in both forward and backward directions\",\n",
    "        \"best_for\": \"When context from both directions matters\",\n",
    "        \"params\": \"~100K-400K\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Transformer\",\n",
    "        \"type\": \"Attention\",\n",
    "        \"description\": \"Self-attention mechanism for parallel processing\",\n",
    "        \"best_for\": \"Long sequences, capturing global dependencies\",\n",
    "        \"params\": \"~200K-1M\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CNN-LSTM\",\n",
    "        \"type\": \"Hybrid\",\n",
    "        \"description\": \"CNN extracts features, LSTM learns temporal patterns\",\n",
    "        \"best_for\": \"Feature extraction + sequence learning\",\n",
    "        \"params\": \"~80K-300K\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"TCN-GNN-LSTM\",\n",
    "        \"type\": \"Advanced Hybrid\",\n",
    "        \"description\": \"Temporal Conv + Graph Neural Network + LSTM\",\n",
    "        \"best_for\": \"Multi-scale patterns with asset relationships\",\n",
    "        \"params\": \"~300K-800K\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DQN (RL)\",\n",
    "        \"type\": \"Reinforcement Learning\",\n",
    "        \"description\": \"Deep Q-Network - Learns optimal trading actions\",\n",
    "        \"best_for\": \"Direct trading signal generation\",\n",
    "        \"params\": \"~100K-500K\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"PPO (RL)\",\n",
    "        \"type\": \"Reinforcement Learning\",\n",
    "        \"description\": \"Proximal Policy Optimization - Stable policy learning\",\n",
    "        \"best_for\": \"Continuous action spaces, portfolio allocation\",\n",
    "        \"params\": \"~150K-600K\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ§  Available Model Architectures:\\n\")\n",
    "for i, model in enumerate(models, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{i}. {model['name']} ({model['type']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   ğŸ“ Description: {model['description']}\")\n",
    "    print(f\"   ğŸ¯ Best For: {model['best_for']}\")\n",
    "    print(f\"   ğŸ“Š Parameters: {model['params']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Single Asset Training & Prediction <a id='7-single-asset-training'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"TRAINING STATUS\")\n",
    "\n",
    "# Check current training status\n",
    "training_status = api_get(\"/training/advanced/status\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Current Training Status:\")\n",
    "print(f\"   Is Training: {training_status.get('is_training', False)}\")\n",
    "print(f\"   Current Model: {training_status.get('current_model', 'N/A')}\")\n",
    "\n",
    "if training_status.get('final_accuracy'):\n",
    "    print(f\"\\nâœ… Last Training Results:\")\n",
    "    print(f\"   Model Type: {training_status.get('model_type', 'N/A')}\")\n",
    "    print(f\"   Final Accuracy: {training_status.get('final_accuracy', 0)*100:.2f}%\")\n",
    "    print(f\"   Total Epochs: {training_status.get('total_epochs', 0)}\")\n",
    "    print(f\"   Current Epoch: {training_status.get('current_epoch', 0)}\")\n",
    "\n",
    "if training_status.get('data_info'):\n",
    "    data_info = training_status['data_info']\n",
    "    print(f\"\\nğŸ“ˆ Training Data Info:\")\n",
    "    print(f\"   Samples: {data_info.get('samples', 0):,}\")\n",
    "    print(f\"   Features: {data_info.get('features', 0)}\")\n",
    "    print(f\"   Class Balance: {data_info.get('class_balance', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"PRICE PREDICTION\")\n",
    "\n",
    "# Make prediction\n",
    "print(\"\\nğŸ”® Making price prediction for BTC/USDT...\")\n",
    "\n",
    "prediction = api_get(\"/predictions/make?symbol=BTC/USDT&use_advanced=true\")\n",
    "\n",
    "if prediction.get('direction_label'):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"          PREDICTION RESULT\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"\\n   Symbol: {prediction.get('symbol')}\")\n",
    "    print(f\"   Current Price: ${prediction.get('current_price', 0):,.2f}\")\n",
    "    print(f\"\\n   ğŸ¯ PREDICTION: {prediction.get('direction_label')}\")\n",
    "    print(f\"   ğŸ“Š Confidence: {prediction.get('confidence', 0)*100:.1f}%\")\n",
    "    print(f\"   ğŸ§  Model: {prediction.get('model_type', 'N/A')}\")\n",
    "    print(f\"   â° Timestamp: {prediction.get('timestamp', 'N/A')}\")\n",
    "    \n",
    "    # Visualize confidence\n",
    "    confidence = prediction.get('confidence', 0)\n",
    "    direction = prediction.get('direction_label', 'HOLD')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 2))\n",
    "    color = '#00d4aa' if direction == 'UP' else '#ef4444' if direction == 'DOWN' else '#f59e0b'\n",
    "    ax.barh([0], [confidence * 100], color=color, height=0.5)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Confidence (%)')\n",
    "    ax.set_title(f'Prediction: {direction} ({confidence*100:.1f}%)', fontsize=12, fontweight='bold')\n",
    "    ax.axvline(x=50, color='white', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print_warning(\"Prediction not available - model may need training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Multi-Asset Portfolio Optimization <a id='8-portfolio-optimization'></a>\n",
    "\n",
    "## Portfolio Optimization Strategies\n",
    "\n",
    "1. **Traditional + ML** - Mean-Variance Optimization with ML-predicted returns\n",
    "2. **Deep Learning** - Neural network directly outputs allocation weights\n",
    "3. **RL Agent (PPO)** - Reinforcement learning for dynamic rebalancing\n",
    "4. **Hybrid Ensemble** - Combines all strategies\n",
    "\n",
    "## Optimization Objectives\n",
    "- **Max Sharpe Ratio** - Best risk-adjusted return\n",
    "- **Max Return** - Aggressive, highest expected return\n",
    "- **Min Risk** - Conservative, lowest volatility\n",
    "- **Risk Parity** - Equal risk contribution from each asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"PORTFOLIO OPTIMIZATION - SETUP\")\n",
    "\n",
    "# Get available assets\n",
    "assets_info = api_get(\"/portfolio/assets\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Portfolio Configuration:\")\n",
    "print(f\"\\n   Available Assets ({assets_info.get('count', 0)}):\")\n",
    "for i, asset in enumerate(assets_info.get('assets', []), 1):\n",
    "    print(f\"      {i:2}. {asset}\")\n",
    "\n",
    "print(f\"\\n   Strategies: {assets_info.get('strategies')}\")\n",
    "print(f\"   Objectives: {assets_info.get('objectives')}\")\n",
    "print(f\"   Horizons: {assets_info.get('horizons')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"FETCHING MULTI-ASSET DATA\")\n",
    "\n",
    "# Select assets for portfolio\n",
    "selected_assets = [\n",
    "    \"BTC/USDT\", \"ETH/USDT\", \"BNB/USDT\", \"SOL/USDT\", \"XRP/USDT\",\n",
    "    \"ADA/USDT\", \"DOGE/USDT\", \"AVAX/USDT\", \"DOT/USDT\", \"MATIC/USDT\"\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Fetching data for {len(selected_assets)} assets...\")\n",
    "print(f\"   Assets: {[a.replace('/USDT', '') for a in selected_assets]}\")\n",
    "\n",
    "fetch_result = api_post(\"/portfolio/fetch-data\", {\n",
    "    \"assets\": selected_assets,\n",
    "    \"timeframe\": \"1d\"\n",
    "})\n",
    "\n",
    "if fetch_result.get('status') == 'success':\n",
    "    print_success(f\"Fetched data for {fetch_result.get('assets_fetched')} assets\")\n",
    "    \n",
    "    # Display asset statistics\n",
    "    if fetch_result.get('statistics'):\n",
    "        print(f\"\\nğŸ“Š Asset Statistics:\")\n",
    "        stats_df = pd.DataFrame(fetch_result['statistics']).T\n",
    "        stats_df = stats_df[['current_price', 'expected_return', 'volatility', 'sharpe_ratio', 'data_points']]\n",
    "        stats_df['current_price'] = stats_df['current_price'].apply(lambda x: f\"${x:,.2f}\")\n",
    "        stats_df['expected_return'] = stats_df['expected_return'].apply(lambda x: f\"{x:+.2f}%\")\n",
    "        stats_df['volatility'] = stats_df['volatility'].apply(lambda x: f\"{x:.2f}%\")\n",
    "        display(stats_df)\n",
    "else:\n",
    "    print_warning(f\"Fetch failed: {fetch_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"PORTFOLIO OPTIMIZATION - ALL 4 STRATEGIES\")\n",
    "\n",
    "investment_amount = 10000\n",
    "\n",
    "print(f\"\\nğŸ’° Investment Amount: ${investment_amount:,}\")\n",
    "print(f\"ğŸ“Š Objective: Maximize Sharpe Ratio\")\n",
    "print(f\"â±ï¸  Horizon: 7 days\")\n",
    "print(f\"\\nğŸ”„ Running optimization with all 4 strategies...\")\n",
    "\n",
    "optimization_result = api_post(\"/portfolio/optimize\", {\n",
    "    \"assets\": selected_assets,\n",
    "    \"investment_amount\": investment_amount,\n",
    "    \"strategy\": \"traditional_ml\",\n",
    "    \"objective\": \"max_sharpe\",\n",
    "    \"horizon\": \"7d\",\n",
    "    \"compare_all\": True,\n",
    "    \"constraints\": {\n",
    "        \"max_weight\": 25,\n",
    "        \"min_assets\": 5\n",
    "    }\n",
    "})\n",
    "\n",
    "if optimization_result.get('status') == 'success':\n",
    "    print_success(\"Optimization complete!\")\n",
    "    print(f\"\\nâ­ Recommended Strategy: {optimization_result.get('recommended', 'N/A').upper()}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"                    STRATEGY COMPARISON\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    strategy_results = []\n",
    "    for strategy_name, strategy_data in optimization_result.get('strategies', {}).items():\n",
    "        status = strategy_data.get('status')\n",
    "        if status == 'success':\n",
    "            metrics = strategy_data.get('metrics', {})\n",
    "            strategy_results.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Expected Return': f\"{metrics.get('expected_return', 0):+.2f}%\",\n",
    "                'Volatility': f\"{metrics.get('volatility', 0):.2f}%\",\n",
    "                'Sharpe Ratio': f\"{metrics.get('sharpe_ratio', 0):.3f}\",\n",
    "                'Assets Used': metrics.get('num_assets', 0),\n",
    "                'Status': 'âœ…'\n",
    "            })\n",
    "        else:\n",
    "            strategy_results.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Expected Return': '-',\n",
    "                'Volatility': '-',\n",
    "                'Sharpe Ratio': '-',\n",
    "                'Assets Used': '-',\n",
    "                'Status': 'â³ Not Trained' if status == 'not_trained' else 'âŒ'\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(strategy_results)\n",
    "    display(results_df)\n",
    "else:\n",
    "    print_warning(f\"Optimization failed: {optimization_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"RECOMMENDED ALLOCATION\")\n",
    "\n",
    "recommended = optimization_result.get('recommended', 'traditional_ml')\n",
    "strategy_data = optimization_result.get('strategies', {}).get(recommended, {})\n",
    "\n",
    "if strategy_data.get('allocations'):\n",
    "    allocations = strategy_data['allocations']\n",
    "    alloc_df = pd.DataFrame(allocations)\n",
    "    \n",
    "    print(f\"\\nğŸ’¼ Strategy: {recommended.upper()}\")\n",
    "    print(f\"ğŸ’° Total Investment: ${investment_amount:,}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    ax1 = axes[0]\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(alloc_df)))\n",
    "    wedges, texts, autotexts = ax1.pie(\n",
    "        alloc_df['weight'], \n",
    "        labels=[a.replace('/USDT', '') for a in alloc_df['symbol']], \n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        explode=[0.02] * len(alloc_df)\n",
    "    )\n",
    "    ax1.set_title('Portfolio Allocation', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Bar chart\n",
    "    ax2 = axes[1]\n",
    "    symbols = [a.replace('/USDT', '') for a in alloc_df['symbol']]\n",
    "    amounts = alloc_df['amount']\n",
    "    bars = ax2.barh(symbols, amounts, color='#00d4aa')\n",
    "    ax2.set_xlabel('Amount ($)', fontsize=12)\n",
    "    ax2.set_title('Investment per Asset', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, amount in zip(bars, amounts):\n",
    "        ax2.text(amount + 50, bar.get_y() + bar.get_height()/2, \n",
    "                f'${amount:,.0f}', va='center', fontsize=10)\n",
    "    \n",
    "    ax2.set_xlim(0, max(amounts) * 1.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print allocation table\n",
    "    print(f\"\\nğŸ“‹ Allocation Details:\")\n",
    "    alloc_df['Amount'] = alloc_df['amount'].apply(lambda x: f\"${x:,.2f}\")\n",
    "    alloc_df['Weight'] = alloc_df['weight'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    alloc_df['Expected Return'] = alloc_df['expected_return'].apply(lambda x: f\"{x:+.2f}%\")\n",
    "    display(alloc_df[['symbol', 'Weight', 'Amount', 'Expected Return']])\n",
    "    \n",
    "    # Portfolio metrics\n",
    "    metrics = strategy_data.get('metrics', {})\n",
    "    print(f\"\\nğŸ“Š Portfolio Metrics:\")\n",
    "    print(f\"   Expected Return: {metrics.get('expected_return', 0):+.2f}%\")\n",
    "    print(f\"   Volatility (Risk): {metrics.get('volatility', 0):.2f}%\")\n",
    "    print(f\"   Sharpe Ratio: {metrics.get('sharpe_ratio', 0):.3f}\")\n",
    "    print(f\"   Assets in Portfolio: {metrics.get('num_assets', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Correlation & Risk Analysis <a id='9-correlation-analysis'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"CORRELATION MATRIX\")\n",
    "\n",
    "correlation = api_get(\"/portfolio/correlation\")\n",
    "\n",
    "if correlation.get('status') == 'success':\n",
    "    corr_data = correlation.get('data', {})\n",
    "    assets = corr_data.get('assets', [])\n",
    "    matrix = np.array(corr_data.get('matrix', []))\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    mask = np.triu(np.ones_like(matrix, dtype=bool), k=1)\n",
    "    cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        matrix, \n",
    "        mask=mask,\n",
    "        annot=True, \n",
    "        fmt='.2f', \n",
    "        cmap=cmap,\n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        xticklabels=assets,\n",
    "        yticklabels=assets,\n",
    "        cbar_kws={'shrink': 0.8},\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Asset Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Best diversification pairs\n",
    "    div_pairs = correlation.get('diversification_pairs', [])\n",
    "    if div_pairs:\n",
    "        print(f\"\\nğŸ¯ Best Diversification Pairs (Low Correlation):\")\n",
    "        for i, pair in enumerate(div_pairs[:10], 1):\n",
    "            print(f\"   {i:2}. {pair[0]:12} â†” {pair[1]:12} : {pair[2]:+.3f}\")\n",
    "else:\n",
    "    print_warning(\"Correlation data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"EFFICIENT FRONTIER\")\n",
    "\n",
    "frontier = api_get(f\"/portfolio/efficient-frontier?assets={','.join(selected_assets)}\")\n",
    "\n",
    "if frontier.get('status') == 'success':\n",
    "    frontier_data = frontier.get('frontier', [])\n",
    "    \n",
    "    if frontier_data:\n",
    "        frontier_df = pd.DataFrame(frontier_data)\n",
    "        \n",
    "        # Create efficient frontier plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Plot frontier\n",
    "        scatter = ax.scatter(\n",
    "            frontier_df['volatility'], \n",
    "            frontier_df['return'],\n",
    "            c=frontier_df['sharpe'],\n",
    "            cmap='viridis',\n",
    "            s=100,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Connect points with line\n",
    "        ax.plot(frontier_df['volatility'], frontier_df['return'], \n",
    "                color='#00d4aa', linewidth=2, alpha=0.5)\n",
    "        \n",
    "        # Mark optimal point (max Sharpe)\n",
    "        optimal_idx = frontier_df['sharpe'].idxmax()\n",
    "        optimal = frontier_df.loc[optimal_idx]\n",
    "        ax.scatter([optimal['volatility']], [optimal['return']], \n",
    "                  color='red', s=300, marker='*', zorder=5, label='Optimal (Max Sharpe)')\n",
    "        \n",
    "        # Labels and formatting\n",
    "        ax.set_xlabel('Risk (Volatility %)', fontsize=12)\n",
    "        ax.set_ylabel('Expected Return (%)', fontsize=12)\n",
    "        ax.set_title('Efficient Frontier - Risk vs Return', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Sharpe Ratio', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nâ­ Optimal Portfolio Point:\")\n",
    "        print(f\"   Expected Return: {optimal['return']:.2f}%\")\n",
    "        print(f\"   Volatility: {optimal['volatility']:.2f}%\")\n",
    "        print(f\"   Sharpe Ratio: {optimal['sharpe']:.3f}\")\n",
    "else:\n",
    "    print_warning(\"Efficient frontier data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Deep Learning Portfolio Strategy <a id='10-deep-learning-portfolio'></a>\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Input (Market Features) â†’ LSTM Encoder â†’ Attention Layer â†’ Dense Layers â†’ Softmax â†’ Portfolio Weights\n",
    "```\n",
    "\n",
    "## Training Objective\n",
    "- **Loss Function**: Negative Sharpe Ratio\n",
    "- **Goal**: Maximize risk-adjusted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"DEEP LEARNING PORTFOLIO MODEL\")\n",
    "\n",
    "model_info = api_get(\"/portfolio/model-info\")\n",
    "\n",
    "print(f\"\\nğŸ§  Deep Learning Model Status:\")\n",
    "print(f\"   Trained: {model_info.get('deep_learning_trained', False)}\")\n",
    "\n",
    "if model_info.get('deep_learning_info'):\n",
    "    dl_info = model_info['deep_learning_info']\n",
    "    print(f\"\\nğŸ“Š Model Details:\")\n",
    "    print(f\"   Assets: {dl_info.get('n_assets', 0)}\")\n",
    "    print(f\"   Lookback Window: {dl_info.get('lookback', 0)} periods\")\n",
    "    print(f\"   Feature Dimension: {dl_info.get('feature_dim', 0)}\")\n",
    "    print(f\"   Total Parameters: {dl_info.get('model_params', 0):,}\")\n",
    "    \n",
    "    if dl_info.get('asset_names'):\n",
    "        print(f\"   Assets Trained On: {dl_info['asset_names']}\")\n",
    "else:\n",
    "    print_info(\"Deep Learning model not trained yet\")\n",
    "    print(\"   To train: Use the Portfolio page or call /api/portfolio/train-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 11. Reinforcement Learning Strategy <a id='11-rl-strategy'></a>\n",
    "\n",
    "## PPO (Proximal Policy Optimization)\n",
    "\n",
    "### Components\n",
    "- **Actor Network**: Outputs portfolio weights (policy)\n",
    "- **Critic Network**: Estimates value function\n",
    "\n",
    "### Environment\n",
    "- **State**: Asset features + current portfolio weights\n",
    "- **Action**: New portfolio weights\n",
    "- **Reward**: Portfolio return - transaction costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"REINFORCEMENT LEARNING PORTFOLIO AGENT\")\n",
    "\n",
    "print(f\"\\nğŸ¤– RL Agent Status:\")\n",
    "print(f\"   Trained: {model_info.get('rl_agent_trained', False)}\")\n",
    "\n",
    "if model_info.get('rl_agent_info'):\n",
    "    rl_info = model_info['rl_agent_info']\n",
    "    print(f\"\\nğŸ“Š Agent Details:\")\n",
    "    print(f\"   Assets: {rl_info.get('n_assets', 0)}\")\n",
    "    \n",
    "    if rl_info.get('training_result'):\n",
    "        tr = rl_info['training_result']\n",
    "        print(f\"\\nğŸ“ˆ Training Results:\")\n",
    "        print(f\"   Episodes: {tr.get('episodes', 0)}\")\n",
    "        print(f\"   Final Portfolio Value: ${tr.get('final_portfolio_value', 0):,.2f}\")\n",
    "        print(f\"   Total Return: {tr.get('total_return', 0):+.2f}%\")\n",
    "        print(f\"   Final Avg Reward: {tr.get('final_avg_reward', 0):.4f}\")\n",
    "    \n",
    "    if rl_info.get('asset_names'):\n",
    "        print(f\"   Assets: {rl_info['asset_names']}\")\n",
    "else:\n",
    "    print_info(\"RL Agent not trained yet\")\n",
    "    print(\"   To train: Use the Portfolio page or call /api/portfolio/train-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 12. Hybrid Ensemble Strategy <a id='12-hybrid-strategy'></a>\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. Get allocation from **Traditional+ML**\n",
    "2. Get allocation from **Deep Learning** (if trained)\n",
    "3. Get allocation from **RL Agent** (if trained)\n",
    "4. **Combine** using weighted average\n",
    "5. Apply **constraints** and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"HYBRID ENSEMBLE STRATEGY\")\n",
    "\n",
    "# Check which strategies are available\n",
    "strategies_available = [\n",
    "    (\"Traditional+ML\", True),\n",
    "    (\"Deep Learning\", model_info.get('deep_learning_trained', False)),\n",
    "    (\"RL Agent\", model_info.get('rl_agent_trained', False))\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“Š Strategies Available for Hybrid:\")\n",
    "for name, available in strategies_available:\n",
    "    status = \"âœ… Available\" if available else \"âŒ Not Trained\"\n",
    "    print(f\"   â€¢ {name}: {status}\")\n",
    "\n",
    "# Get hybrid allocation if available\n",
    "hybrid_data = optimization_result.get('strategies', {}).get('hybrid', {})\n",
    "\n",
    "if hybrid_data.get('status') == 'success':\n",
    "    print(f\"\\nğŸ”€ Hybrid Allocation Results:\")\n",
    "    metrics = hybrid_data.get('metrics', {})\n",
    "    print(f\"   Expected Return: {metrics.get('expected_return', 0):+.2f}%\")\n",
    "    print(f\"   Volatility: {metrics.get('volatility', 0):.2f}%\")\n",
    "    print(f\"   Sharpe Ratio: {metrics.get('sharpe_ratio', 0):.3f}\")\n",
    "    \n",
    "    if hybrid_data.get('strategies_combined'):\n",
    "        print(f\"\\n   Strategies Combined: {hybrid_data['strategies_combined']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 13. Model Persistence <a id='13-model-persistence'></a>\n",
    "\n",
    "## Features\n",
    "- **Save** trained models to disk\n",
    "- **Load** models without retraining\n",
    "- **Delete** unused models\n",
    "- **List** all saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"SAVED PORTFOLIO MODELS\")\n",
    "\n",
    "saved_models = api_get(\"/portfolio/models/list\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Total Saved Models: {saved_models.get('total_models', 0)}\")\n",
    "\n",
    "# Deep Learning Models\n",
    "dl_models = saved_models.get('deep_learning_models', [])\n",
    "print(f\"\\nğŸ§  Deep Learning Models ({len(dl_models)}):\")\n",
    "if dl_models:\n",
    "    for model in dl_models:\n",
    "        print(f\"   â”Œâ”€ {model['model_name']}\")\n",
    "        print(f\"   â”‚  Assets: {model.get('n_assets', 0)}\")\n",
    "        print(f\"   â”‚  Parameters: {model.get('model_params', 0):,}\")\n",
    "        print(f\"   â””â”€ Created: {model.get('created_at', 'N/A')}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"   No saved DL models\")\n",
    "\n",
    "# RL Models\n",
    "rl_models = saved_models.get('rl_agent_models', [])\n",
    "print(f\"\\nğŸ¤– RL Agent Models ({len(rl_models)}):\")\n",
    "if rl_models:\n",
    "    for model in rl_models:\n",
    "        print(f\"   â”Œâ”€ {model['model_name']}\")\n",
    "        print(f\"   â”‚  Assets: {model.get('n_assets', 0)}\")\n",
    "        if model.get('training_result'):\n",
    "            tr = model['training_result']\n",
    "            print(f\"   â”‚  Training Return: {tr.get('total_return', 0):+.2f}%\")\n",
    "            print(f\"   â”‚  Episodes: {tr.get('episodes', 0)}\")\n",
    "        print(f\"   â””â”€ Created: {model.get('created_at', 'N/A')}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"   No saved RL models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loading a saved model\n",
    "print_header(\"MODEL LOAD DEMONSTRATION\")\n",
    "\n",
    "if dl_models:\n",
    "    model_to_load = dl_models[0]\n",
    "    print(f\"\\nğŸ“‚ Loading model: {model_to_load['model_name']}\")\n",
    "    \n",
    "    load_result = api_post(\"/portfolio/models/load\", {\n",
    "        \"model_type\": \"deep_learning\",\n",
    "        \"model_path\": model_to_load['model_path']\n",
    "    })\n",
    "    \n",
    "    if load_result.get('status') == 'success':\n",
    "        print_success(\"Model loaded successfully!\")\n",
    "        print(f\"   Assets: {load_result.get('n_assets', 0)}\")\n",
    "        print(f\"   Asset Names: {load_result.get('asset_names', [])}\")\n",
    "    else:\n",
    "        print_warning(f\"Load failed: {load_result.get('message', 'Unknown error')}\")\n",
    "else:\n",
    "    print_info(\"No saved models to demonstrate loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 14. Backtesting <a id='14-backtesting'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"BACKTESTING STATUS\")\n",
    "\n",
    "backtest_status = api_get(\"/backtest/status\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Backtest System Status:\")\n",
    "print(f\"   Is Running: {backtest_status.get('is_running', False)}\")\n",
    "\n",
    "# Get backtest history\n",
    "backtest_history = api_get(\"/backtest/history?limit=5\")\n",
    "\n",
    "if backtest_history.get('history'):\n",
    "    print(f\"\\nğŸ“œ Recent Backtests ({backtest_history.get('count', 0)}):\")\n",
    "    for bt in backtest_history['history']:\n",
    "        print(f\"   â€¢ {bt.get('created_at', 'N/A')[:19]}\")\n",
    "        if bt.get('metrics'):\n",
    "            m = bt['metrics']\n",
    "            print(f\"     Total Return: {m.get('total_return', 0):+.2f}%\")\n",
    "            print(f\"     Win Rate: {m.get('win_rate', 0):.1f}%\")\n",
    "else:\n",
    "    print_info(\"No backtest history available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 15. AI Advisor Integration <a id='15-ai-advisor'></a>\n",
    "\n",
    "## Supported LLMs\n",
    "- **OpenAI GPT-4o**\n",
    "- **Anthropic Claude**\n",
    "- **Google Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"AI ADVISOR\")\n",
    "\n",
    "print(\"\\nğŸ¤– Testing AI Advisor...\")\n",
    "print(\"   Model: GPT-4o\")\n",
    "print(\"   Query: Market analysis request\\n\")\n",
    "\n",
    "advisor_response = api_post(\"/llm/chat\", {\n",
    "    \"message\": \"Give me a brief 2-sentence analysis of the current Bitcoin market conditions.\",\n",
    "    \"model\": \"gpt-4o\"\n",
    "})\n",
    "\n",
    "if advisor_response.get('response'):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"AI ADVISOR RESPONSE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n{advisor_response['response']}\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Model: {advisor_response.get('model', 'N/A')}\")\n",
    "else:\n",
    "    print_warning(f\"AI Advisor error: {advisor_response.get('error', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 16. Complete Workflow Demo <a id='16-complete-workflow'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_trading_workflow(investment_amount=10000):\n",
    "    \"\"\"\n",
    "    Execute complete trading system workflow:\n",
    "    Data â†’ Analysis â†’ Optimization â†’ Recommendation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"         ğŸš€ COMPLETE TRADING SYSTEM WORKFLOW ğŸš€\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Fetch Data\n",
    "    print(\"\\n[STEP 1/5] ğŸ“ˆ Fetching Multi-Asset Data...\")\n",
    "    assets = [\"BTC/USDT\", \"ETH/USDT\", \"BNB/USDT\", \"SOL/USDT\", \"XRP/USDT\"]\n",
    "    fetch = api_post(\"/portfolio/fetch-data\", {\"assets\": assets, \"timeframe\": \"1d\"})\n",
    "    print(f\"           âœ… Fetched data for {fetch.get('assets_fetched', 0)} assets\")\n",
    "    results['data_fetched'] = fetch.get('assets_fetched', 0)\n",
    "    \n",
    "    # Step 2: Single Asset Prediction\n",
    "    print(\"\\n[STEP 2/5] ğŸ”® Making BTC Price Prediction...\")\n",
    "    prediction = api_get(\"/predictions/make?symbol=BTC/USDT&use_advanced=true\")\n",
    "    if prediction.get('direction_label'):\n",
    "        print(f\"           âœ… BTC Prediction: {prediction['direction_label']} ({prediction['confidence']*100:.1f}% confidence)\")\n",
    "        results['btc_prediction'] = prediction['direction_label']\n",
    "        results['btc_confidence'] = prediction['confidence']\n",
    "    \n",
    "    # Step 3: Correlation Analysis\n",
    "    print(\"\\n[STEP 3/5] ğŸ”— Analyzing Asset Correlations...\")\n",
    "    corr = api_get(\"/portfolio/correlation\")\n",
    "    if corr.get('diversification_pairs'):\n",
    "        best = corr['diversification_pairs'][0]\n",
    "        print(f\"           âœ… Best diversification: {best[0]} â†” {best[1]} (corr: {best[2]})\")\n",
    "        results['best_diversification'] = f\"{best[0]} â†” {best[1]}\"\n",
    "    \n",
    "    # Step 4: Portfolio Optimization\n",
    "    print(\"\\n[STEP 4/5] ğŸ¯ Optimizing Portfolio Allocation...\")\n",
    "    opt = api_post(\"/portfolio/optimize\", {\n",
    "        \"assets\": assets,\n",
    "        \"investment_amount\": investment_amount,\n",
    "        \"objective\": \"max_sharpe\",\n",
    "        \"compare_all\": True,\n",
    "        \"constraints\": {\"max_weight\": 30, \"min_assets\": 3}\n",
    "    })\n",
    "    if opt.get('status') == 'success':\n",
    "        print(f\"           âœ… Recommended strategy: {opt['recommended']}\")\n",
    "        results['recommended_strategy'] = opt['recommended']\n",
    "    \n",
    "    # Step 5: Final Recommendation\n",
    "    print(\"\\n[STEP 5/5] ğŸ’¼ Generating Final Recommendation...\")\n",
    "    \n",
    "    recommended = opt.get('recommended', 'traditional_ml')\n",
    "    strategy_data = opt.get('strategies', {}).get(recommended, {})\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"                    ğŸ“Š FINAL RECOMMENDATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if strategy_data.get('allocations'):\n",
    "        print(f\"\\nğŸ’° Investment: ${investment_amount:,}\")\n",
    "        print(f\"ğŸ“ˆ Strategy: {recommended.upper()}\")\n",
    "        print(f\"\\nâ”Œ{'â”€'*50}â”\")\n",
    "        print(f\"â”‚{'OPTIMAL PORTFOLIO ALLOCATION':^50}â”‚\")\n",
    "        print(f\"â”œ{'â”€'*50}â”¤\")\n",
    "        \n",
    "        for alloc in strategy_data['allocations']:\n",
    "            symbol = alloc['symbol'].replace('/USDT', '')\n",
    "            weight = alloc['weight']\n",
    "            amount = alloc['amount']\n",
    "            bar = 'â–ˆ' * int(weight / 2)\n",
    "            print(f\"â”‚ {symbol:6} {bar:15} {weight:5.1f}% ${amount:>8,.0f} â”‚\")\n",
    "        \n",
    "        print(f\"â””{'â”€'*50}â”˜\")\n",
    "        \n",
    "        metrics = strategy_data.get('metrics', {})\n",
    "        print(f\"\\nğŸ“Š Expected Performance:\")\n",
    "        print(f\"   â€¢ Expected Return: {metrics.get('expected_return', 0):+.2f}%\")\n",
    "        print(f\"   â€¢ Risk (Volatility): {metrics.get('volatility', 0):.2f}%\")\n",
    "        print(f\"   â€¢ Sharpe Ratio: {metrics.get('sharpe_ratio', 0):.3f}\")\n",
    "        \n",
    "        results['expected_return'] = metrics.get('expected_return', 0)\n",
    "        results['risk'] = metrics.get('volatility', 0)\n",
    "        results['sharpe'] = metrics.get('sharpe_ratio', 0)\n",
    "        results['allocations'] = strategy_data['allocations']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"         âœ… WORKFLOW COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Execute the complete workflow\n",
    "workflow_results = complete_trading_workflow(investment_amount=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## System Capabilities Demonstrated\n",
    "\n",
    "| Feature | Status | Description |\n",
    "|---------|--------|-------------|\n",
    "| Multi-Exchange Data | âœ… | Binance, OKX, and more |\n",
    "| Arbitrary Date Range | âœ… | Fetch data from 2017 to today |\n",
    "| Feature Engineering | âœ… | 30+ technical indicators |\n",
    "| Price Prediction | âœ… | 11+ neural network architectures |\n",
    "| Portfolio Optimization | âœ… | 4 AI strategies |\n",
    "| Correlation Analysis | âœ… | Asset correlation heatmap |\n",
    "| Efficient Frontier | âœ… | Risk-return optimization |\n",
    "| Model Persistence | âœ… | Save/Load/Delete models |\n",
    "| AI Advisor | âœ… | GPT-4o, Claude, Gemini |\n",
    "\n",
    "## Key API Endpoints\n",
    "\n",
    "| Endpoint | Method | Description |\n",
    "|----------|--------|-------------|\n",
    "| `/api/market-data` | GET | Fetch OHLCV data |\n",
    "| `/api/predictions/make` | GET | Get price prediction |\n",
    "| `/api/training/advanced/start` | POST | Start model training |\n",
    "| `/api/portfolio/fetch-data` | POST | Fetch multi-asset data |\n",
    "| `/api/portfolio/optimize` | POST | Get optimal allocation |\n",
    "| `/api/portfolio/correlation` | GET | Correlation matrix |\n",
    "| `/api/portfolio/models/list` | GET | List saved models |\n",
    "| `/api/portfolio/models/save` | POST | Save trained model |\n",
    "| `/api/portfolio/models/load` | POST | Load saved model |\n",
    "| `/api/llm/chat` | POST | AI Advisor chat |\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
