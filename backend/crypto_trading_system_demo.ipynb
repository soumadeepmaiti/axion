{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Input Hybrid Deep Learning System for Crypto Portfolio Optimization\n",
    "\n",
    "## A Complete Backend Demonstration Notebook\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. **Introduction & System Architecture**\n",
    "2. **Data Pipeline - Multi-Asset OHLCV Fetching**\n",
    "3. **Feature Engineering - Technical Indicators**\n",
    "4. **Correlation Analysis - Asset Relationships**\n",
    "5. **Return Prediction - ML Models**\n",
    "6. **Portfolio Optimization - 4 AI Strategies**\n",
    "   - Strategy A: Traditional Mean-Variance + ML\n",
    "   - Strategy B: Deep Learning Portfolio Network\n",
    "   - Strategy C: Reinforcement Learning Agent (PPO)\n",
    "   - Strategy D: Hybrid Ensemble\n",
    "7. **Performance Evaluation & Backtesting**\n",
    "8. **Model Persistence - Save/Load/Delete**\n",
    "9. **Conclusion & Future Enhancements**\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** AI Trading System  \n",
    "**Version:** 2.0  \n",
    "**Last Updated:** February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction & System Architecture\n",
    "\n",
    "### 1.1 Problem Statement\n",
    "\n",
    "The goal of this system is to build a **multi-input hybrid deep learning system** for cryptocurrency trading that:\n",
    "\n",
    "1. **Predicts price direction** (UP/DOWN) for multiple crypto assets\n",
    "2. **Optimizes capital allocation** across assets to maximize risk-adjusted returns\n",
    "3. **Compares multiple AI strategies** to find the best approach\n",
    "\n",
    "### 1.2 System Architecture\n",
    "\n",
    "```\n",
    "+------------------+     +-------------------+     +--------------------+\n",
    "|   Data Pipeline  | --> | Feature Engineering| --> |  Return Prediction |\n",
    "|  (CCXT/Binance)  |     |  (99 Features)     |     |  (LSTM per asset)  |\n",
    "+------------------+     +-------------------+     +--------------------+\n",
    "                                                           |\n",
    "                                                           v\n",
    "+------------------+     +-------------------+     +--------------------+\n",
    "| Model Persistence| <-- |Strategy Comparison| <-- |Portfolio Optimizer |\n",
    "|  (Save/Load)     |     |  (4 Strategies)   |     |  (MVO, DL, RL)     |\n",
    "+------------------+     +-------------------+     +--------------------+\n",
    "```\n",
    "\n",
    "### 1.3 Key Technologies\n",
    "\n",
    "- **Data Fetching:** CCXT library (supports 100+ exchanges)\n",
    "- **Feature Engineering:** ta (technical analysis), numpy, pandas\n",
    "- **ML Framework:** TensorFlow/Keras, scikit-learn, XGBoost\n",
    "- **Optimization:** scipy, PyPortfolioOpt\n",
    "- **Reinforcement Learning:** Custom PPO implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Environment Setup\n",
    "\n",
    "First, let's import all necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Data fetching\n",
    "import ccxt\n",
    "\n",
    "# Technical analysis\n",
    "import ta\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Dense, Dropout, BatchNormalization, \n",
    "    Input, Attention, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Optimization\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CRYPTO PORTFOLIO OPTIMIZATION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Timestamp: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Pipeline - Multi-Asset OHLCV Fetching\n",
    "\n",
    "### 3.1 Understanding OHLCV Data\n",
    "\n",
    "**OHLCV** stands for:\n",
    "- **O**pen: Price at the beginning of the period\n",
    "- **H**igh: Highest price during the period\n",
    "- **L**ow: Lowest price during the period\n",
    "- **C**lose: Price at the end of the period\n",
    "- **V**olume: Total trading volume\n",
    "\n",
    "### 3.2 Exchange Configuration\n",
    "\n",
    "We use the CCXT library which provides a unified API for 100+ cryptocurrency exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize exchange (Binance US for public data)\n",
    "exchange = ccxt.binanceus({\n",
    "    'enableRateLimit': True,  # Respect rate limits\n",
    "    'options': {'defaultType': 'spot'}\n",
    "})\n",
    "\n",
    "print(f\"Exchange: {exchange.name}\")\n",
    "print(f\"Timeframes available: {list(exchange.timeframes.keys())}\")\n",
    "print(f\"Rate limit enabled: {exchange.enableRateLimit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Define Assets for Portfolio\n",
    "\n",
    "We'll work with a diversified set of cryptocurrencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define portfolio assets (Top cryptocurrencies by market cap and liquidity)\n",
    "PORTFOLIO_ASSETS = [\n",
    "    \"BTC/USDT\",   # Bitcoin - The original cryptocurrency\n",
    "    \"ETH/USDT\",   # Ethereum - Smart contract platform\n",
    "    \"BNB/USDT\",   # Binance Coin - Exchange token\n",
    "    \"SOL/USDT\",   # Solana - High-speed blockchain\n",
    "    \"XRP/USDT\",   # Ripple - Payment protocol\n",
    "]\n",
    "\n",
    "print(\"Portfolio Assets:\")\n",
    "for i, asset in enumerate(PORTFOLIO_ASSETS, 1):\n",
    "    print(f\"  {i}. {asset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data Fetching Function\n",
    "\n",
    "This function fetches historical OHLCV data with support for arbitrary date ranges using chunked requests to avoid API timeouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ohlcv(symbol, timeframe='1d', limit=365, since=None):\n",
    "    \"\"\"\n",
    "    Fetch OHLCV data for a symbol.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    symbol : str\n",
    "        Trading pair (e.g., 'BTC/USDT')\n",
    "    timeframe : str\n",
    "        Candle timeframe ('1m', '5m', '15m', '1h', '4h', '1d')\n",
    "    limit : int\n",
    "        Maximum number of candles to fetch\n",
    "    since : datetime, optional\n",
    "        Start date for fetching data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        OHLCV data with datetime index\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert datetime to milliseconds if provided\n",
    "        since_ms = int(since.timestamp() * 1000) if since else None\n",
    "        \n",
    "        # Fetch data\n",
    "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since_ms, limit)\n",
    "        \n",
    "        if not ohlcv:\n",
    "            print(f\"  Warning: No data returned for {symbol}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching {symbol}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"fetch_ohlcv() function defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Fetch Data for All Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Fetch data for all portfolio assets\n",
    "print(\"Fetching OHLCV data for portfolio assets...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "price_data = {}\n",
    "DAYS_OF_DATA = 365  # 1 year of daily data\n",
    "\n",
    "for asset in PORTFOLIO_ASSETS:\n",
    "    print(f\"Fetching {asset}...\", end=\" \")\n",
    "    df = fetch_ohlcv(asset, timeframe='1d', limit=DAYS_OF_DATA)\n",
    "    \n",
    "    if not df.empty:\n",
    "        price_data[asset] = df\n",
    "        print(f\"OK ({len(df)} candles, {df.index.min().date()} to {df.index.max().date()})\")\n",
    "    else:\n",
    "        print(\"FAILED\")\n",
    "    \n",
    "    time.sleep(0.2)  # Rate limiting\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Successfully fetched data for {len(price_data)}/{len(PORTFOLIO_ASSETS)} assets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Visualize Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price history for all assets (normalized)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Absolute prices\n",
    "ax1 = axes[0]\n",
    "for asset, df in price_data.items():\n",
    "    ax1.plot(df.index, df['close'], label=asset.replace('/USDT', ''), linewidth=1.5)\n",
    "ax1.set_title('Cryptocurrency Prices (Absolute)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price (USDT)')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')  # Log scale for better visualization\n",
    "\n",
    "# Plot 2: Normalized prices (start = 100)\n",
    "ax2 = axes[1]\n",
    "for asset, df in price_data.items():\n",
    "    normalized = (df['close'] / df['close'].iloc[0]) * 100\n",
    "    ax2.plot(df.index, normalized, label=asset.replace('/USDT', ''), linewidth=1.5)\n",
    "ax2.axhline(y=100, color='white', linestyle='--', alpha=0.5, label='Starting Value')\n",
    "ax2.set_title('Cryptocurrency Prices (Normalized to 100)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Normalized Price')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Feature Engineering - Technical Indicators\n",
    "\n",
    "### 4.1 Understanding Technical Analysis\n",
    "\n",
    "Technical analysis uses historical price and volume data to predict future price movements. We calculate the following categories of indicators:\n",
    "\n",
    "| Category | Indicators | Purpose |\n",
    "|----------|------------|---------|\n",
    "| **Trend** | SMA, EMA, MACD | Identify market direction |\n",
    "| **Momentum** | RSI, Stochastic, ROC | Measure speed of price changes |\n",
    "| **Volatility** | ATR, Bollinger Bands | Measure price fluctuations |\n",
    "| **Volume** | OBV, MFI, Volume Ratio | Confirm price movements |\n",
    "\n",
    "### 4.2 Technical Indicator Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive technical indicators for a price DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        OHLCV data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with all technical indicators added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ==========================================\n",
    "    # TREND INDICATORS\n",
    "    # ==========================================\n",
    "    \n",
    "    # Simple Moving Averages (SMA)\n",
    "    df['sma_10'] = ta.trend.sma_indicator(df['close'], window=10)\n",
    "    df['sma_20'] = ta.trend.sma_indicator(df['close'], window=20)\n",
    "    df['sma_50'] = ta.trend.sma_indicator(df['close'], window=50)\n",
    "    \n",
    "    # Exponential Moving Averages (EMA)\n",
    "    df['ema_12'] = ta.trend.ema_indicator(df['close'], window=12)\n",
    "    df['ema_26'] = ta.trend.ema_indicator(df['close'], window=26)\n",
    "    \n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    macd = ta.trend.MACD(df['close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    df['macd'] = macd.macd()\n",
    "    df['macd_signal'] = macd.macd_signal()\n",
    "    df['macd_hist'] = macd.macd_diff()\n",
    "    \n",
    "    # ADX (Average Directional Index) - Trend Strength\n",
    "    adx = ta.trend.ADXIndicator(df['high'], df['low'], df['close'], window=14)\n",
    "    df['adx'] = adx.adx()\n",
    "    df['di_plus'] = adx.adx_pos()\n",
    "    df['di_minus'] = adx.adx_neg()\n",
    "    \n",
    "    # ==========================================\n",
    "    # MOMENTUM INDICATORS\n",
    "    # ==========================================\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    df['rsi'] = ta.momentum.rsi(df['close'], window=14)\n",
    "    df['rsi_6'] = ta.momentum.rsi(df['close'], window=6)\n",
    "    df['rsi_24'] = ta.momentum.rsi(df['close'], window=24)\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'], window=14, smooth_window=3)\n",
    "    df['stoch_k'] = stoch.stoch()\n",
    "    df['stoch_d'] = stoch.stoch_signal()\n",
    "    \n",
    "    # ROC (Rate of Change)\n",
    "    df['roc_10'] = ta.momentum.roc(df['close'], window=10)\n",
    "    \n",
    "    # ==========================================\n",
    "    # VOLATILITY INDICATORS\n",
    "    # ==========================================\n",
    "    \n",
    "    # ATR (Average True Range)\n",
    "    df['atr'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14)\n",
    "    df['atr_percent'] = df['atr'] / df['close'] * 100\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb = ta.volatility.BollingerBands(df['close'], window=20, window_dev=2)\n",
    "    df['bb_upper'] = bb.bollinger_hband()\n",
    "    df['bb_middle'] = bb.bollinger_mavg()\n",
    "    df['bb_lower'] = bb.bollinger_lband()\n",
    "    df['bb_width'] = bb.bollinger_wband()\n",
    "    df['bb_percent'] = bb.bollinger_pband()\n",
    "    \n",
    "    # ==========================================\n",
    "    # VOLUME INDICATORS\n",
    "    # ==========================================\n",
    "    \n",
    "    # OBV (On-Balance Volume)\n",
    "    df['obv'] = ta.volume.on_balance_volume(df['close'], df['volume'])\n",
    "    \n",
    "    # MFI (Money Flow Index)\n",
    "    df['mfi'] = ta.volume.money_flow_index(df['high'], df['low'], df['close'], df['volume'], window=14)\n",
    "    \n",
    "    # Volume ratio to moving average\n",
    "    df['volume_sma_20'] = df['volume'].rolling(20).mean()\n",
    "    df['volume_ratio'] = df['volume'] / df['volume_sma_20']\n",
    "    \n",
    "    # ==========================================\n",
    "    # PRICE RATIOS & RETURNS\n",
    "    # ==========================================\n",
    "    \n",
    "    # Price ratios to moving averages\n",
    "    df['price_sma20_ratio'] = df['close'] / df['sma_20']\n",
    "    df['price_sma50_ratio'] = df['close'] / df['sma_50']\n",
    "    \n",
    "    # Returns\n",
    "    df['return_1'] = df['close'].pct_change(1)\n",
    "    df['return_5'] = df['close'].pct_change(5)\n",
    "    df['return_10'] = df['close'].pct_change(10)\n",
    "    df['return_20'] = df['close'].pct_change(20)\n",
    "    \n",
    "    # Volatility (rolling std of returns)\n",
    "    df['volatility_10'] = df['return_1'].rolling(10).std()\n",
    "    df['volatility_20'] = df['return_1'].rolling(20).std()\n",
    "    \n",
    "    # Momentum\n",
    "    df['momentum_10'] = df['close'] - df['close'].shift(10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"calculate_technical_indicators() function defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Apply Feature Engineering to All Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply technical indicators to all assets\n",
    "print(\"Calculating technical indicators for all assets...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "for asset, df in price_data.items():\n",
    "    print(f\"Processing {asset}...\", end=\" \")\n",
    "    processed_df = calculate_technical_indicators(df)\n",
    "    processed_data[asset] = processed_df\n",
    "    print(f\"OK ({len(processed_df.columns)} features)\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show sample of features for BTC\n",
    "if 'BTC/USDT' in processed_data:\n",
    "    sample_df = processed_data['BTC/USDT']\n",
    "    print(f\"\\nSample Features for BTC/USDT (last 5 rows):\")\n",
    "    display(sample_df[['close', 'rsi', 'macd', 'atr_percent', 'bb_percent', 'volume_ratio']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key indicators for BTC\n",
    "if 'BTC/USDT' in processed_data:\n",
    "    btc = processed_data['BTC/USDT'].dropna()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 12), sharex=True)\n",
    "    \n",
    "    # Price with Bollinger Bands\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(btc.index, btc['close'], label='Close Price', color='cyan', linewidth=1.5)\n",
    "    ax1.fill_between(btc.index, btc['bb_lower'], btc['bb_upper'], alpha=0.2, color='yellow')\n",
    "    ax1.plot(btc.index, btc['sma_20'], '--', label='SMA 20', color='orange', linewidth=1)\n",
    "    ax1.set_title('BTC/USDT Price with Bollinger Bands', fontweight='bold')\n",
    "    ax1.set_ylabel('Price (USDT)')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # RSI\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(btc.index, btc['rsi'], color='magenta', linewidth=1.5)\n",
    "    ax2.axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Overbought (70)')\n",
    "    ax2.axhline(y=30, color='green', linestyle='--', alpha=0.7, label='Oversold (30)')\n",
    "    ax2.fill_between(btc.index, 30, 70, alpha=0.1, color='white')\n",
    "    ax2.set_title('RSI (Relative Strength Index)', fontweight='bold')\n",
    "    ax2.set_ylabel('RSI')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MACD\n",
    "    ax3 = axes[2]\n",
    "    ax3.plot(btc.index, btc['macd'], label='MACD', color='cyan', linewidth=1.5)\n",
    "    ax3.plot(btc.index, btc['macd_signal'], label='Signal', color='orange', linewidth=1)\n",
    "    colors = ['green' if x > 0 else 'red' for x in btc['macd_hist']]\n",
    "    ax3.bar(btc.index, btc['macd_hist'], color=colors, alpha=0.5, width=1)\n",
    "    ax3.axhline(y=0, color='white', linestyle='-', alpha=0.3)\n",
    "    ax3.set_title('MACD (Moving Average Convergence Divergence)', fontweight='bold')\n",
    "    ax3.set_ylabel('MACD')\n",
    "    ax3.legend(loc='upper left')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Volume\n",
    "    ax4 = axes[3]\n",
    "    ax4.bar(btc.index, btc['volume'], color='lightblue', alpha=0.7, width=1)\n",
    "    ax4.plot(btc.index, btc['volume_sma_20'], color='yellow', linewidth=1.5, label='20-day MA')\n",
    "    ax4.set_title('Trading Volume', fontweight='bold')\n",
    "    ax4.set_ylabel('Volume')\n",
    "    ax4.set_xlabel('Date')\n",
    "    ax4.legend(loc='upper left')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Correlation Analysis - Asset Relationships\n",
    "\n",
    "### 5.1 Understanding Correlation in Portfolio Management\n",
    "\n",
    "**Correlation** measures how assets move together:\n",
    "- **+1.0**: Perfect positive correlation (move together)\n",
    "- **0.0**: No correlation (independent)\n",
    "- **-1.0**: Perfect negative correlation (move opposite)\n",
    "\n",
    "For portfolio diversification, we want assets with **low or negative correlation** to reduce overall risk.\n",
    "\n",
    "### 5.2 Calculate Returns for All Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns for all assets\n",
    "returns_data = {}\n",
    "\n",
    "print(\"Calculating returns for correlation analysis...\")\n",
    "for asset, df in price_data.items():\n",
    "    # Log returns have better statistical properties\n",
    "    returns = np.log(df['close'] / df['close'].shift(1))\n",
    "    returns_data[asset] = returns.dropna()\n",
    "    print(f\"  {asset}: {len(returns_data[asset])} return observations\")\n",
    "\n",
    "# Create returns DataFrame\n",
    "returns_df = pd.DataFrame(returns_data)\n",
    "returns_df = returns_df.dropna()  # Align all series to common dates\n",
    "\n",
    "print(f\"\\nAligned returns: {len(returns_df)} observations across {len(returns_df.columns)} assets\")\n",
    "print(f\"Date range: {returns_df.index.min().date()} to {returns_df.index.max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = returns_df.corr()\n",
    "\n",
    "# Display as heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Clean up asset names for display\n",
    "clean_names = [name.replace('/USDT', '') for name in correlation_matrix.columns]\n",
    "correlation_display = correlation_matrix.copy()\n",
    "correlation_display.columns = clean_names\n",
    "correlation_display.index = clean_names\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    correlation_display,\n",
    "    annot=True,\n",
    "    fmt='.3f',\n",
    "    cmap='RdYlGn',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title('Asset Correlation Matrix (Log Returns)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best diversification pairs (lowest correlation)\n",
    "print(\"\\nBest Diversification Pairs (lowest correlation):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "pairs = []\n",
    "for i, asset1 in enumerate(correlation_matrix.columns):\n",
    "    for j, asset2 in enumerate(correlation_matrix.columns):\n",
    "        if i < j:\n",
    "            corr = correlation_matrix.loc[asset1, asset2]\n",
    "            pairs.append((asset1.replace('/USDT', ''), asset2.replace('/USDT', ''), corr))\n",
    "\n",
    "pairs.sort(key=lambda x: x[2])\n",
    "for asset1, asset2, corr in pairs[:5]:\n",
    "    print(f\"  {asset1} <-> {asset2}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Covariance Matrix\n",
    "\n",
    "The **covariance matrix** is essential for Mean-Variance Optimization. It captures both variance (diagonal) and co-movement (off-diagonal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance matrix (annualized)\n",
    "# Crypto markets trade 365 days/year\n",
    "TRADING_DAYS = 365\n",
    "\n",
    "cov_matrix = returns_df.cov() * TRADING_DAYS  # Annualize\n",
    "\n",
    "print(\"Annualized Covariance Matrix:\")\n",
    "cov_display = cov_matrix.copy()\n",
    "cov_display.columns = clean_names\n",
    "cov_display.index = clean_names\n",
    "display(cov_display.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Asset Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected returns and volatility for each asset\n",
    "expected_returns = returns_df.mean() * TRADING_DAYS  # Annualized\n",
    "volatility = returns_df.std() * np.sqrt(TRADING_DAYS)  # Annualized\n",
    "sharpe_ratios = expected_returns / volatility  # Simplified Sharpe (risk-free = 0)\n",
    "\n",
    "# Create summary table\n",
    "asset_stats = pd.DataFrame({\n",
    "    'Asset': clean_names,\n",
    "    'Expected Return (%)': (expected_returns.values * 100).round(2),\n",
    "    'Volatility (%)': (volatility.values * 100).round(2),\n",
    "    'Sharpe Ratio': sharpe_ratios.values.round(3),\n",
    "    'Current Price': [price_data[a]['close'].iloc[-1] for a in returns_df.columns]\n",
    "})\n",
    "\n",
    "print(\"\\nAsset Statistics (Annualized):\")\n",
    "print(\"=\" * 70)\n",
    "display(asset_stats.set_index('Asset'))\n",
    "\n",
    "# Visualize risk-return profile\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(clean_names)))\n",
    "\n",
    "for i, (name, ret, vol) in enumerate(zip(clean_names, expected_returns.values * 100, volatility.values * 100)):\n",
    "    ax.scatter(vol, ret, s=200, c=[colors[i]], label=name, edgecolors='white', linewidth=2)\n",
    "    ax.annotate(name, (vol, ret), xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Annualized Volatility (%)', fontsize=12)\n",
    "ax.set_ylabel('Annualized Expected Return (%)', fontsize=12)\n",
    "ax.set_title('Risk-Return Profile of Portfolio Assets', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='white', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Portfolio Optimization - 4 AI Strategies\n",
    "\n",
    "Now we implement and compare **four distinct portfolio optimization strategies**:\n",
    "\n",
    "| Strategy | Approach | Key Concept |\n",
    "|----------|----------|-------------|\n",
    "| **A. Traditional + ML** | Mean-Variance Optimization | Markowitz Modern Portfolio Theory |\n",
    "| **B. Deep Learning** | Neural Network | End-to-end weight prediction |\n",
    "| **C. Reinforcement Learning** | PPO Agent | Learn by trading simulation |\n",
    "| **D. Hybrid Ensemble** | Weighted Average | Combine all strategies |\n",
    "\n",
    "---\n",
    "\n",
    "## 6.1 Strategy A: Traditional Mean-Variance Optimization (MVO)\n",
    "\n",
    "### 6.1.1 Mathematical Foundation\n",
    "\n",
    "**Modern Portfolio Theory (MPT)**, developed by Harry Markowitz in 1952, optimizes the trade-off between risk and return.\n",
    "\n",
    "**Key Equations:**\n",
    "\n",
    "**Portfolio Return:**\n",
    "$$R_p = \\sum_{i=1}^{n} w_i \\cdot r_i = \\mathbf{w}^T \\mathbf{r}$$\n",
    "\n",
    "**Portfolio Variance:**\n",
    "$$\\sigma_p^2 = \\sum_{i=1}^{n} \\sum_{j=1}^{n} w_i \\cdot w_j \\cdot \\sigma_{ij} = \\mathbf{w}^T \\mathbf{\\Sigma} \\mathbf{w}$$\n",
    "\n",
    "**Sharpe Ratio (Risk-Adjusted Return):**\n",
    "$$\\text{Sharpe} = \\frac{R_p - R_f}{\\sigma_p}$$\n",
    "\n",
    "Where:\n",
    "- $w_i$ = weight of asset $i$\n",
    "- $r_i$ = expected return of asset $i$\n",
    "- $\\sigma_{ij}$ = covariance between assets $i$ and $j$\n",
    "- $R_f$ = risk-free rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanVarianceOptimizer:\n",
    "    \"\"\"\n",
    "    Traditional Mean-Variance Portfolio Optimizer (Markowitz)\n",
    "    \n",
    "    This optimizer finds the optimal asset weights that maximize\n",
    "    risk-adjusted returns (Sharpe Ratio) given expected returns\n",
    "    and the covariance matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, expected_returns, cov_matrix, risk_free_rate=0.05):\n",
    "        \"\"\"\n",
    "        Initialize the optimizer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        expected_returns : array-like\n",
    "            Expected annual returns for each asset\n",
    "        cov_matrix : array-like\n",
    "            Annualized covariance matrix\n",
    "        risk_free_rate : float\n",
    "            Annual risk-free rate (default: 5%)\n",
    "        \"\"\"\n",
    "        self.expected_returns = np.array(expected_returns)\n",
    "        self.cov_matrix = np.array(cov_matrix)\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.n_assets = len(expected_returns)\n",
    "        \n",
    "    def portfolio_return(self, weights):\n",
    "        \"\"\"Calculate portfolio expected return\"\"\"\n",
    "        return np.dot(weights, self.expected_returns)\n",
    "    \n",
    "    def portfolio_volatility(self, weights):\n",
    "        \"\"\"Calculate portfolio volatility (standard deviation)\"\"\"\n",
    "        return np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))\n",
    "    \n",
    "    def sharpe_ratio(self, weights):\n",
    "        \"\"\"Calculate Sharpe Ratio\"\"\"\n",
    "        ret = self.portfolio_return(weights)\n",
    "        vol = self.portfolio_volatility(weights)\n",
    "        return (ret - self.risk_free_rate) / vol if vol > 0 else 0\n",
    "    \n",
    "    def negative_sharpe(self, weights):\n",
    "        \"\"\"Negative Sharpe for minimization\"\"\"\n",
    "        return -self.sharpe_ratio(weights)\n",
    "    \n",
    "    def optimize(self, objective='max_sharpe', max_weight=0.4, min_weight=0.0):\n",
    "        \"\"\"\n",
    "        Find optimal portfolio weights.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        objective : str\n",
    "            'max_sharpe' (default), 'min_risk', or 'max_return'\n",
    "        max_weight : float\n",
    "            Maximum weight per asset (default: 40%)\n",
    "        min_weight : float\n",
    "            Minimum weight per asset (default: 0%)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Optimization result with weights and metrics\n",
    "        \"\"\"\n",
    "        # Initial guess: equal weights\n",
    "        init_weights = np.array([1.0 / self.n_assets] * self.n_assets)\n",
    "        \n",
    "        # Constraints: weights must sum to 1\n",
    "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]\n",
    "        \n",
    "        # Bounds: min_weight <= w_i <= max_weight\n",
    "        bounds = tuple((min_weight, max_weight) for _ in range(self.n_assets))\n",
    "        \n",
    "        # Select objective function\n",
    "        if objective == 'max_sharpe':\n",
    "            obj_func = self.negative_sharpe\n",
    "        elif objective == 'min_risk':\n",
    "            obj_func = self.portfolio_volatility\n",
    "        elif objective == 'max_return':\n",
    "            obj_func = lambda w: -self.portfolio_return(w)\n",
    "        else:\n",
    "            obj_func = self.negative_sharpe\n",
    "        \n",
    "        # Run optimization\n",
    "        result = minimize(\n",
    "            obj_func,\n",
    "            init_weights,\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints,\n",
    "            options={'maxiter': 1000}\n",
    "        )\n",
    "        \n",
    "        optimal_weights = result.x\n",
    "        \n",
    "        # Calculate metrics\n",
    "        return {\n",
    "            'weights': optimal_weights,\n",
    "            'expected_return': self.portfolio_return(optimal_weights),\n",
    "            'volatility': self.portfolio_volatility(optimal_weights),\n",
    "            'sharpe_ratio': self.sharpe_ratio(optimal_weights),\n",
    "            'success': result.success\n",
    "        }\n",
    "\n",
    "print(\"MeanVarianceOptimizer class defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Run Mean-Variance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "mvo = MeanVarianceOptimizer(\n",
    "    expected_returns=expected_returns.values,\n",
    "    cov_matrix=cov_matrix.values,\n",
    "    risk_free_rate=0.05  # 5% annual risk-free rate\n",
    ")\n",
    "\n",
    "# Run optimization with Max Sharpe objective\n",
    "print(\"Running Mean-Variance Optimization (Max Sharpe Ratio)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mvo_result = mvo.optimize(\n",
    "    objective='max_sharpe',\n",
    "    max_weight=0.40,  # Max 40% in any single asset\n",
    "    min_weight=0.05   # Min 5% in any asset (diversification)\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimization Status: {'SUCCESS' if mvo_result['success'] else 'FAILED'}\")\n",
    "print(f\"\\nPortfolio Metrics:\")\n",
    "print(f\"  Expected Annual Return: {mvo_result['expected_return']*100:.2f}%\")\n",
    "print(f\"  Annual Volatility: {mvo_result['volatility']*100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {mvo_result['sharpe_ratio']:.3f}\")\n",
    "\n",
    "print(f\"\\nOptimal Asset Weights:\")\n",
    "print(\"-\" * 40)\n",
    "for asset, weight in zip(clean_names, mvo_result['weights']):\n",
    "    bar = '█' * int(weight * 50)\n",
    "    print(f\"  {asset:6} {bar:25} {weight*100:5.1f}%\")\n",
    "\n",
    "# Store for comparison\n",
    "strategy_a_weights = dict(zip(returns_df.columns, mvo_result['weights']))\n",
    "strategy_a_metrics = mvo_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Efficient Frontier\n",
    "\n",
    "The **Efficient Frontier** shows all optimal portfolios that offer the highest expected return for a given level of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_efficient_frontier(optimizer, n_points=50):\n",
    "    \"\"\"\n",
    "    Calculate points along the efficient frontier.\n",
    "    \"\"\"\n",
    "    frontier_points = []\n",
    "    \n",
    "    # Range of target returns\n",
    "    min_ret = optimizer.expected_returns.min()\n",
    "    max_ret = optimizer.expected_returns.max()\n",
    "    target_returns = np.linspace(min_ret, max_ret, n_points)\n",
    "    \n",
    "    for target_ret in target_returns:\n",
    "        try:\n",
    "            # Minimize volatility for target return\n",
    "            init_weights = np.array([1.0 / optimizer.n_assets] * optimizer.n_assets)\n",
    "            bounds = tuple((0.0, 1.0) for _ in range(optimizer.n_assets))\n",
    "            \n",
    "            constraints = [\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},\n",
    "                {'type': 'eq', 'fun': lambda w, t=target_ret: optimizer.portfolio_return(w) - t}\n",
    "            ]\n",
    "            \n",
    "            result = minimize(\n",
    "                optimizer.portfolio_volatility,\n",
    "                init_weights,\n",
    "                method='SLSQP',\n",
    "                bounds=bounds,\n",
    "                constraints=constraints,\n",
    "                options={'maxiter': 500}\n",
    "            )\n",
    "            \n",
    "            if result.success:\n",
    "                vol = optimizer.portfolio_volatility(result.x)\n",
    "                ret = optimizer.portfolio_return(result.x)\n",
    "                sharpe = optimizer.sharpe_ratio(result.x)\n",
    "                frontier_points.append({'return': ret, 'volatility': vol, 'sharpe': sharpe})\n",
    "                \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(frontier_points)\n",
    "\n",
    "# Calculate efficient frontier\n",
    "print(\"Calculating Efficient Frontier...\")\n",
    "frontier = calculate_efficient_frontier(mvo, n_points=30)\n",
    "print(f\"Generated {len(frontier)} frontier points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Efficient Frontier\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot frontier curve\n",
    "ax.plot(\n",
    "    frontier['volatility'] * 100, \n",
    "    frontier['return'] * 100, \n",
    "    'cyan', linewidth=3, label='Efficient Frontier'\n",
    ")\n",
    "\n",
    "# Plot individual assets\n",
    "for i, (name, ret, vol) in enumerate(zip(clean_names, expected_returns.values * 100, volatility.values * 100)):\n",
    "    ax.scatter(vol, ret, s=150, marker='o', edgecolors='white', linewidth=2, zorder=5)\n",
    "    ax.annotate(name, (vol, ret), xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "# Plot optimal portfolio (Max Sharpe)\n",
    "opt_vol = mvo_result['volatility'] * 100\n",
    "opt_ret = mvo_result['expected_return'] * 100\n",
    "ax.scatter(opt_vol, opt_ret, s=300, marker='*', color='gold', edgecolors='white', \n",
    "           linewidth=2, zorder=10, label=f'Optimal Portfolio (Sharpe={mvo_result[\"sharpe_ratio\"]:.3f})')\n",
    "\n",
    "# Capital Market Line (CML)\n",
    "rf = 5  # Risk-free rate %\n",
    "slope = (opt_ret - rf) / opt_vol\n",
    "x_cml = np.linspace(0, opt_vol * 1.5, 100)\n",
    "y_cml = rf + slope * x_cml\n",
    "ax.plot(x_cml, y_cml, '--', color='yellow', linewidth=1.5, alpha=0.7, label='Capital Market Line')\n",
    "\n",
    "ax.set_xlabel('Annual Volatility (%)', fontsize=12)\n",
    "ax.set_ylabel('Annual Expected Return (%)', fontsize=12)\n",
    "ax.set_title('Efficient Frontier & Optimal Portfolio', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='white', linestyle='-', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6.2 Strategy B: Deep Learning Portfolio Network\n",
    "\n",
    "### 6.2.1 Concept\n",
    "\n",
    "Instead of using traditional optimization, we train a **neural network** to directly output portfolio weights. The model learns to maximize risk-adjusted returns through backpropagation.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (lookback × features) → LSTM → Attention → Dense → Softmax → Weights\n",
    "```\n",
    "\n",
    "**Custom Loss Function (Negative Sharpe Ratio):**\n",
    "$$\\mathcal{L} = -\\frac{\\mathbb{E}[R_p]}{\\sqrt{\\text{Var}(R_p)}} + \\lambda \\sum_i w_i^2$$\n",
    "\n",
    "The second term penalizes concentration to encourage diversification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPortfolioNetwork:\n",
    "    \"\"\"\n",
    "    Deep Learning model that directly outputs optimal portfolio weights.\n",
    "    \n",
    "    The network is trained to maximize Sharpe Ratio using a custom loss function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_assets, lookback=30):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_assets : int\n",
    "            Number of assets in portfolio\n",
    "        lookback : int\n",
    "            Number of historical periods to consider\n",
    "        \"\"\"\n",
    "        self.n_assets = n_assets\n",
    "        self.lookback = lookback\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def _sharpe_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Custom loss: Negative Sharpe Ratio + Concentration Penalty\n",
    "        \n",
    "        y_true: Future returns (batch, n_assets)\n",
    "        y_pred: Predicted weights (batch, n_assets)\n",
    "        \"\"\"\n",
    "        # Portfolio returns\n",
    "        portfolio_returns = tf.reduce_sum(y_pred * y_true, axis=1)\n",
    "        \n",
    "        # Sharpe ratio components\n",
    "        mean_return = tf.reduce_mean(portfolio_returns)\n",
    "        std_return = tf.math.reduce_std(portfolio_returns) + 1e-6\n",
    "        sharpe = mean_return / std_return\n",
    "        \n",
    "        # Concentration penalty (Herfindahl index)\n",
    "        concentration = tf.reduce_mean(tf.reduce_sum(tf.square(y_pred), axis=1))\n",
    "        \n",
    "        return -sharpe + 0.1 * concentration\n",
    "    \n",
    "    def build_model(self, input_shape):\n",
    "        \"\"\"\n",
    "        Build the neural network architecture.\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=input_shape, name='market_data')\n",
    "        \n",
    "        # LSTM layers for temporal pattern recognition\n",
    "        x = LSTM(64, return_sequences=True)(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = LSTM(32, return_sequences=True)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention = Attention()([x, x])\n",
    "        x = GlobalAveragePooling1D()(attention)\n",
    "        \n",
    "        # Dense layers for portfolio decision\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        \n",
    "        # Output: Portfolio weights (softmax ensures sum = 1)\n",
    "        outputs = Dense(self.n_assets, activation='softmax', name='weights')(x)\n",
    "        \n",
    "        self.model = Model(inputs, outputs, name='DeepPortfolioNetwork')\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=self._sharpe_loss\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def prepare_data(self, price_data_dict, returns_df):\n",
    "        \"\"\"\n",
    "        Prepare training data from price and returns data.\n",
    "        \n",
    "        Returns X (features) and y (future returns).\n",
    "        \"\"\"\n",
    "        self.scaler = RobustScaler()\n",
    "        asset_list = list(price_data_dict.keys())\n",
    "        \n",
    "        # Build feature matrix for each asset\n",
    "        all_features = []\n",
    "        \n",
    "        for asset in asset_list:\n",
    "            df = price_data_dict[asset]\n",
    "            features = pd.DataFrame(index=df.index)\n",
    "            \n",
    "            # Features: return, volatility, momentum, volume change\n",
    "            features['return'] = df['close'].pct_change()\n",
    "            features['volatility'] = features['return'].rolling(10).std()\n",
    "            features['momentum'] = df['close'] / df['close'].shift(5) - 1\n",
    "            features['volume_change'] = df['volume'].pct_change()\n",
    "            \n",
    "            all_features.append(features.dropna())\n",
    "        \n",
    "        # Align all to common index\n",
    "        common_index = all_features[0].index\n",
    "        for f in all_features[1:]:\n",
    "            common_index = common_index.intersection(f.index)\n",
    "        \n",
    "        # Stack features\n",
    "        stacked = np.hstack([f.loc[common_index].values for f in all_features])\n",
    "        stacked_scaled = self.scaler.fit_transform(stacked)\n",
    "        stacked_scaled = np.nan_to_num(stacked_scaled, 0)\n",
    "        \n",
    "        # Align returns\n",
    "        returns_aligned = returns_df.loc[common_index]\n",
    "        \n",
    "        # Create sequences\n",
    "        X, y = [], []\n",
    "        for i in range(self.lookback, len(stacked_scaled) - 1):\n",
    "            X.append(stacked_scaled[i-self.lookback:i])\n",
    "            # Future returns\n",
    "            future_ret = returns_aligned.iloc[i].values\n",
    "            y.append(np.nan_to_num(future_ret, 0))\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def train(self, price_data_dict, returns_df, epochs=50, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the deep portfolio network.\n",
    "        \"\"\"\n",
    "        X, y = self.prepare_data(price_data_dict, returns_df)\n",
    "        \n",
    "        if len(X) < 50:\n",
    "            return {'status': 'failed', 'reason': 'insufficient_data'}\n",
    "        \n",
    "        # Build model\n",
    "        self.build_model(input_shape=(X.shape[1], X.shape[2]))\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "        ]\n",
    "        \n",
    "        # Train\n",
    "        history = self.model.fit(\n",
    "            X, y,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        self.is_trained = True\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'epochs_run': len(history.history['loss']),\n",
    "            'final_loss': min(history.history['val_loss']),\n",
    "            'history': history.history\n",
    "        }\n",
    "    \n",
    "    def predict_weights(self, price_data_dict, returns_df):\n",
    "        \"\"\"\n",
    "        Predict optimal weights for current market state.\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            return None\n",
    "        \n",
    "        X, _ = self.prepare_data(price_data_dict, returns_df)\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Predict on latest data\n",
    "        weights = self.model.predict(X[-1:], verbose=0)[0]\n",
    "        \n",
    "        return weights\n",
    "\n",
    "print(\"DeepPortfolioNetwork class defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Train the Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Deep Portfolio Network\n",
    "print(\"Training Deep Learning Portfolio Network...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dl_network = DeepPortfolioNetwork(n_assets=len(PORTFOLIO_ASSETS), lookback=30)\n",
    "\n",
    "dl_result = dl_network.train(\n",
    "    price_data_dict=price_data,\n",
    "    returns_df=returns_df,\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Status: {dl_result['status'].upper()}\")\n",
    "print(f\"Epochs Run: {dl_result.get('epochs_run', 0)}\")\n",
    "print(f\"Final Loss: {dl_result.get('final_loss', 'N/A')}\")\n",
    "\n",
    "# Get predicted weights\n",
    "if dl_result['status'] == 'success':\n",
    "    dl_weights = dl_network.predict_weights(price_data, returns_df)\n",
    "    \n",
    "    print(f\"\\nPredicted Asset Weights (Deep Learning):\")\n",
    "    print(\"-\" * 40)\n",
    "    for asset, weight in zip(clean_names, dl_weights):\n",
    "        bar = '█' * int(weight * 50)\n",
    "        print(f\"  {asset:6} {bar:25} {weight*100:5.1f}%\")\n",
    "    \n",
    "    strategy_b_weights = dict(zip(returns_df.columns, dl_weights))\n",
    "else:\n",
    "    # Fallback to equal weights\n",
    "    dl_weights = np.ones(len(PORTFOLIO_ASSETS)) / len(PORTFOLIO_ASSETS)\n",
    "    strategy_b_weights = dict(zip(returns_df.columns, dl_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "if dl_result['status'] == 'success' and 'history' in dl_result:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    ax.plot(dl_result['history']['loss'], label='Training Loss', color='cyan', linewidth=2)\n",
    "    ax.plot(dl_result['history']['val_loss'], label='Validation Loss', color='orange', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss (Negative Sharpe + Penalty)')\n",
    "    ax.set_title('Deep Portfolio Network Training Progress', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6.3 Strategy C: Reinforcement Learning Agent (PPO)\n",
    "\n",
    "### 6.3.1 Concept\n",
    "\n",
    "**Reinforcement Learning** trains an agent to make sequential decisions by learning from rewards.\n",
    "\n",
    "**PPO (Proximal Policy Optimization):**\n",
    "- **Actor** network: Outputs action (portfolio weights)\n",
    "- **Critic** network: Estimates value of current state\n",
    "- **Clipped surrogate objective** prevents too large policy updates\n",
    "\n",
    "**Trading Environment:**\n",
    "- **State**: Market features + current portfolio weights\n",
    "- **Action**: New portfolio weights\n",
    "- **Reward**: Risk-adjusted return minus transaction costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioEnvironment:\n",
    "    \"\"\"\n",
    "    Gym-style environment for portfolio management.\n",
    "    \n",
    "    The agent learns to rebalance the portfolio to maximize\n",
    "    risk-adjusted returns while minimizing transaction costs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, price_data_dict, returns_df, initial_capital=10000, transaction_cost=0.001):\n",
    "        self.price_data = price_data_dict\n",
    "        self.returns_df = returns_df.dropna()\n",
    "        self.initial_capital = initial_capital\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        self.asset_names = list(price_data_dict.keys())\n",
    "        self.n_assets = len(self.asset_names)\n",
    "        self.n_steps = len(self.returns_df)\n",
    "        \n",
    "        # State: 5 features per asset + current weights\n",
    "        self.n_features = 5\n",
    "        self.state_dim = self.n_assets * self.n_features + self.n_assets\n",
    "        self.action_dim = self.n_assets\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def _get_features(self, step):\n",
    "        \"\"\"Get market features for current step.\"\"\"\n",
    "        features = np.zeros((self.n_assets, self.n_features))\n",
    "        \n",
    "        for i, asset in enumerate(self.asset_names):\n",
    "            df = self.price_data[asset]\n",
    "            if step >= len(df):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Return, volatility, momentum, volume change, price ratio\n",
    "                features[i, 0] = df['close'].pct_change().iloc[step] if step > 0 else 0\n",
    "                if step >= 10:\n",
    "                    features[i, 1] = df['close'].pct_change().iloc[step-10:step].std()\n",
    "                if step >= 5:\n",
    "                    features[i, 2] = df['close'].iloc[step] / df['close'].iloc[step-5] - 1\n",
    "                features[i, 3] = df['volume'].pct_change().iloc[step] if step > 0 else 0\n",
    "                if step >= 20:\n",
    "                    sma = df['close'].iloc[step-20:step].mean()\n",
    "                    features[i, 4] = df['close'].iloc[step] / sma - 1 if sma > 0 else 0\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        return np.nan_to_num(features, 0)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to initial state.\"\"\"\n",
    "        self.current_step = 20  # Start after warmup\n",
    "        self.current_weights = np.ones(self.n_assets) / self.n_assets\n",
    "        self.portfolio_value = self.initial_capital\n",
    "        self.history = []\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"Get current state as flat array.\"\"\"\n",
    "        features = self._get_features(self.current_step)\n",
    "        return np.concatenate([features.flatten(), self.current_weights])\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute action (rebalance portfolio).\n",
    "        \n",
    "        Returns: next_state, reward, done, info\n",
    "        \"\"\"\n",
    "        # Normalize action to valid weights\n",
    "        action = np.clip(action, 0, 1)\n",
    "        new_weights = action / action.sum() if action.sum() > 0 else np.ones(self.n_assets) / self.n_assets\n",
    "        \n",
    "        # Transaction costs\n",
    "        weight_changes = np.abs(new_weights - self.current_weights)\n",
    "        costs = np.sum(weight_changes) * self.transaction_cost * self.portfolio_value\n",
    "        \n",
    "        # Get returns\n",
    "        step_returns = np.zeros(self.n_assets)\n",
    "        for i, asset in enumerate(self.asset_names):\n",
    "            if asset in self.returns_df.columns and self.current_step < len(self.returns_df):\n",
    "                ret = self.returns_df[asset].iloc[self.current_step]\n",
    "                step_returns[i] = ret if not np.isnan(ret) else 0\n",
    "        \n",
    "        # Portfolio return\n",
    "        portfolio_return = np.dot(new_weights, step_returns)\n",
    "        self.portfolio_value = self.portfolio_value * (1 + portfolio_return) - costs\n",
    "        self.current_weights = new_weights\n",
    "        \n",
    "        # Reward: risk-adjusted return - trading penalty\n",
    "        reward = portfolio_return - 0.5 * (portfolio_return ** 2) - np.sum(weight_changes) * 0.01\n",
    "        \n",
    "        # Move to next step\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.n_steps - 1\n",
    "        \n",
    "        self.history.append({\n",
    "            'step': self.current_step,\n",
    "            'weights': new_weights.copy(),\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'return': portfolio_return\n",
    "        })\n",
    "        \n",
    "        return self._get_state(), float(reward), done, {'portfolio_value': self.portfolio_value}\n",
    "\n",
    "print(\"PortfolioEnvironment class defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent:\n",
    "    \"\"\"\n",
    "    Proximal Policy Optimization (PPO) agent for portfolio management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64, lr=3e-4, gamma=0.99):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Build networks\n",
    "        self._build_networks()\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def _build_networks(self):\n",
    "        \"\"\"Build actor (policy) and critic (value) networks.\"\"\"\n",
    "        # Actor: state -> action probabilities\n",
    "        actor_input = Input(shape=(self.state_dim,))\n",
    "        x = Dense(self.hidden_dim, activation='relu')(actor_input)\n",
    "        x = Dense(self.hidden_dim // 2, activation='relu')(x)\n",
    "        actor_output = Dense(self.action_dim, activation='softmax')(x)\n",
    "        self.actor = Model(actor_input, actor_output, name='actor')\n",
    "        self.actor.compile(optimizer=tf.keras.optimizers.Adam(self.lr))\n",
    "        \n",
    "        # Critic: state -> value estimate\n",
    "        critic_input = Input(shape=(self.state_dim,))\n",
    "        x = Dense(self.hidden_dim, activation='relu')(critic_input)\n",
    "        x = Dense(self.hidden_dim // 2, activation='relu')(x)\n",
    "        critic_output = Dense(1)(x)\n",
    "        self.critic = Model(critic_input, critic_output, name='critic')\n",
    "        self.critic.compile(optimizer=tf.keras.optimizers.Adam(self.lr), loss='mse')\n",
    "    \n",
    "    def get_action(self, state, training=False):\n",
    "        \"\"\"Get action from actor network.\"\"\"\n",
    "        action = self.actor.predict(state.reshape(1, -1), verbose=0)[0]\n",
    "        \n",
    "        if training:\n",
    "            # Add exploration noise\n",
    "            noise = np.random.normal(0, 0.1, size=action.shape)\n",
    "            action = np.clip(action + noise, 0, 1)\n",
    "            action = action / action.sum()\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def train(self, env, n_episodes=30):\n",
    "        \"\"\"\n",
    "        Train the PPO agent.\n",
    "        \"\"\"\n",
    "        episode_rewards = []\n",
    "        episode_values = []\n",
    "        \n",
    "        for episode in range(n_episodes):\n",
    "            state = env.reset()\n",
    "            episode_reward = 0\n",
    "            \n",
    "            states, actions, rewards, values = [], [], [], []\n",
    "            \n",
    "            while True:\n",
    "                action = self.get_action(state, training=True)\n",
    "                value = self.critic.predict(state.reshape(1, -1), verbose=0)[0, 0]\n",
    "                \n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                \n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                values.append(value)\n",
    "                \n",
    "                episode_reward += reward\n",
    "                state = next_state\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            episode_rewards.append(episode_reward)\n",
    "            episode_values.append(env.portfolio_value)\n",
    "            \n",
    "            # Update networks\n",
    "            if len(states) > 0:\n",
    "                states = np.array(states)\n",
    "                actions = np.array(actions)\n",
    "                rewards = np.array(rewards)\n",
    "                values = np.array(values)\n",
    "                \n",
    "                # Calculate returns\n",
    "                returns = np.zeros_like(rewards)\n",
    "                running_return = 0\n",
    "                for t in reversed(range(len(rewards))):\n",
    "                    running_return = rewards[t] + self.gamma * running_return\n",
    "                    returns[t] = running_return\n",
    "                \n",
    "                # Advantages\n",
    "                advantages = returns - values\n",
    "                advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "                \n",
    "                # Update critic\n",
    "                self.critic.fit(states, returns, epochs=3, batch_size=32, verbose=0)\n",
    "                \n",
    "                # Update actor\n",
    "                with tf.GradientTape() as tape:\n",
    "                    action_probs = self.actor(states)\n",
    "                    log_probs = tf.math.log(tf.reduce_sum(action_probs * actions, axis=1) + 1e-8)\n",
    "                    actor_loss = -tf.reduce_mean(log_probs * advantages)\n",
    "                \n",
    "                grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "                self.actor.optimizer.apply_gradients(zip(grads, self.actor.trainable_variables))\n",
    "            \n",
    "            if (episode + 1) % 10 == 0:\n",
    "                print(f\"  Episode {episode+1}/{n_episodes}: Avg Reward={np.mean(episode_rewards[-10:]):.4f}, \"\n",
    "                      f\"Portfolio=${np.mean(episode_values[-10:]):.2f}\")\n",
    "        \n",
    "        self.is_trained = True\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'episodes': n_episodes,\n",
    "            'final_avg_reward': float(np.mean(episode_rewards[-10:])),\n",
    "            'final_portfolio_value': float(episode_values[-1]),\n",
    "            'total_return': float((episode_values[-1] / env.initial_capital - 1) * 100),\n",
    "            'episode_values': episode_values\n",
    "        }\n",
    "\n",
    "print(\"PPOAgent class defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Train the RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment and agent\n",
    "print(\"Training Reinforcement Learning (PPO) Agent...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "env = PortfolioEnvironment(\n",
    "    price_data_dict=price_data,\n",
    "    returns_df=returns_df,\n",
    "    initial_capital=10000,\n",
    "    transaction_cost=0.001  # 0.1% per trade\n",
    ")\n",
    "\n",
    "print(f\"Environment created: {env.n_assets} assets, {env.n_steps} time steps\")\n",
    "print(f\"State dimension: {env.state_dim}, Action dimension: {env.action_dim}\")\n",
    "print()\n",
    "\n",
    "# Create and train agent\n",
    "ppo_agent = PPOAgent(\n",
    "    state_dim=env.state_dim,\n",
    "    action_dim=env.action_dim,\n",
    "    hidden_dim=64,\n",
    "    lr=3e-4,\n",
    "    gamma=0.99\n",
    ")\n",
    "\n",
    "rl_result = ppo_agent.train(env, n_episodes=30)\n",
    "\n",
    "print()\n",
    "print(f\"Training Status: {rl_result['status'].upper()}\")\n",
    "print(f\"Final Portfolio Value: ${rl_result['final_portfolio_value']:.2f}\")\n",
    "print(f\"Total Return: {rl_result['total_return']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RL agent's recommended weights\n",
    "state = env.reset()\n",
    "rl_weights = ppo_agent.get_action(state, training=False)\n",
    "\n",
    "print(f\"\\nPredicted Asset Weights (RL Agent):\")\n",
    "print(\"-\" * 40)\n",
    "for asset, weight in zip(clean_names, rl_weights):\n",
    "    bar = '█' * int(weight * 50)\n",
    "    print(f\"  {asset:6} {bar:25} {weight*100:5.1f}%\")\n",
    "\n",
    "strategy_c_weights = dict(zip(returns_df.columns, rl_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RL training progress\n",
    "if 'episode_values' in rl_result:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    episodes = range(1, len(rl_result['episode_values']) + 1)\n",
    "    ax.plot(episodes, rl_result['episode_values'], color='lime', linewidth=2)\n",
    "    ax.axhline(y=10000, color='white', linestyle='--', alpha=0.5, label='Initial Capital')\n",
    "    \n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.set_ylabel('Portfolio Value ($)')\n",
    "    ax.set_title('RL Agent Training: Portfolio Value per Episode', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6.4 Strategy D: Hybrid Ensemble\n",
    "\n",
    "### 6.4.1 Concept\n",
    "\n",
    "The **Hybrid Ensemble** strategy combines the predictions from all three strategies:\n",
    "\n",
    "$$w_{hybrid} = \\alpha \\cdot w_{MVO} + \\beta \\cdot w_{DL} + \\gamma \\cdot w_{RL}$$\n",
    "\n",
    "Where $\\alpha + \\beta + \\gamma = 1$.\n",
    "\n",
    "By default, we use equal weighting: $\\alpha = \\beta = \\gamma = \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hybrid_weights(strategy_weights_list, ensemble_weights=None):\n",
    "    \"\"\"\n",
    "    Calculate hybrid ensemble weights.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strategy_weights_list : list of arrays\n",
    "        List of weight arrays from each strategy\n",
    "    ensemble_weights : array-like, optional\n",
    "        Weight given to each strategy (default: equal)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    array\n",
    "        Hybrid portfolio weights\n",
    "    \"\"\"\n",
    "    n_strategies = len(strategy_weights_list)\n",
    "    \n",
    "    if ensemble_weights is None:\n",
    "        ensemble_weights = np.ones(n_strategies) / n_strategies\n",
    "    \n",
    "    # Weighted average\n",
    "    hybrid = np.zeros_like(strategy_weights_list[0])\n",
    "    for i, weights in enumerate(strategy_weights_list):\n",
    "        hybrid += ensemble_weights[i] * np.array(weights)\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    hybrid = hybrid / hybrid.sum()\n",
    "    \n",
    "    return hybrid\n",
    "\n",
    "# Calculate hybrid weights\n",
    "print(\"Calculating Hybrid Ensemble Weights...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get weights from each strategy\n",
    "mvo_weights_array = mvo_result['weights']\n",
    "dl_weights_array = dl_weights\n",
    "rl_weights_array = rl_weights\n",
    "\n",
    "# Calculate hybrid (equal weighting)\n",
    "hybrid_weights = calculate_hybrid_weights(\n",
    "    [mvo_weights_array, dl_weights_array, rl_weights_array],\n",
    "    ensemble_weights=[1/3, 1/3, 1/3]\n",
    ")\n",
    "\n",
    "print(f\"\\nPredicted Asset Weights (Hybrid Ensemble):\")\n",
    "print(\"-\" * 40)\n",
    "for asset, weight in zip(clean_names, hybrid_weights):\n",
    "    bar = '█' * int(weight * 50)\n",
    "    print(f\"  {asset:6} {bar:25} {weight*100:5.1f}%\")\n",
    "\n",
    "strategy_d_weights = dict(zip(returns_df.columns, hybrid_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Strategy Comparison\n",
    "\n",
    "Let's compare all four strategies side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for all strategies\n",
    "def calculate_portfolio_metrics(weights, expected_returns, cov_matrix, risk_free=0.05):\n",
    "    \"\"\"Calculate return, volatility, and Sharpe for given weights.\"\"\"\n",
    "    ret = np.dot(weights, expected_returns)\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe = (ret - risk_free) / vol if vol > 0 else 0\n",
    "    return ret, vol, sharpe\n",
    "\n",
    "# All strategies\n",
    "strategies = {\n",
    "    'Traditional (MVO)': mvo_weights_array,\n",
    "    'Deep Learning': dl_weights_array,\n",
    "    'RL Agent (PPO)': rl_weights_array,\n",
    "    'Hybrid Ensemble': hybrid_weights\n",
    "}\n",
    "\n",
    "# Calculate metrics\n",
    "comparison_data = []\n",
    "for name, weights in strategies.items():\n",
    "    ret, vol, sharpe = calculate_portfolio_metrics(\n",
    "        weights, expected_returns.values, cov_matrix.values\n",
    "    )\n",
    "    comparison_data.append({\n",
    "        'Strategy': name,\n",
    "        'Expected Return (%)': round(ret * 100, 2),\n",
    "        'Volatility (%)': round(vol * 100, 2),\n",
    "        'Sharpe Ratio': round(sharpe, 3)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STRATEGY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "display(comparison_df.set_index('Strategy'))\n",
    "\n",
    "# Find best strategy\n",
    "best_idx = comparison_df['Sharpe Ratio'].idxmax()\n",
    "best_strategy = comparison_df.loc[best_idx, 'Strategy']\n",
    "print(f\"\\n★ RECOMMENDED STRATEGY: {best_strategy} (Highest Sharpe Ratio)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize strategy comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Weight allocation comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(clean_names))\n",
    "width = 0.2\n",
    "\n",
    "colors = ['cyan', 'magenta', 'lime', 'gold']\n",
    "for i, (name, weights) in enumerate(strategies.items()):\n",
    "    ax1.bar(x + i * width, weights * 100, width, label=name, color=colors[i], alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Asset')\n",
    "ax1.set_ylabel('Weight (%)')\n",
    "ax1.set_title('Portfolio Weight Allocation by Strategy', fontweight='bold')\n",
    "ax1.set_xticks(x + width * 1.5)\n",
    "ax1.set_xticklabels(clean_names)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Risk-Return scatter\n",
    "ax2 = axes[1]\n",
    "for i, (name, row) in enumerate(comparison_df.iterrows()):\n",
    "    ax2.scatter(\n",
    "        row['Volatility (%)'], row['Expected Return (%)'],\n",
    "        s=300, c=[colors[i]], label=row['Strategy'],\n",
    "        edgecolors='white', linewidth=2\n",
    "    )\n",
    "    ax2.annotate(\n",
    "        f\"  {row['Strategy']}\\n  Sharpe: {row['Sharpe Ratio']}\",\n",
    "        (row['Volatility (%)'], row['Expected Return (%)']),\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "ax2.set_xlabel('Volatility (%)')\n",
    "ax2.set_ylabel('Expected Return (%)')\n",
    "ax2.set_title('Risk-Return Profile by Strategy', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Investment Allocation Example\n",
    "\n",
    "Let's see how a $10,000 investment would be allocated using the **recommended strategy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment allocation\n",
    "INVESTMENT_AMOUNT = 10000\n",
    "\n",
    "# Use the best strategy's weights\n",
    "best_weights = strategies[best_strategy]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"INVESTMENT ALLOCATION (${INVESTMENT_AMOUNT:,})\")\n",
    "print(f\"Strategy: {best_strategy}\")\n",
    "print(f\"{'='*60}\")\n",
    "print()\n",
    "\n",
    "allocation_data = []\n",
    "for i, (asset, weight) in enumerate(zip(clean_names, best_weights)):\n",
    "    amount = INVESTMENT_AMOUNT * weight\n",
    "    current_price = price_data[list(price_data.keys())[i]]['close'].iloc[-1]\n",
    "    units = amount / current_price if current_price > 0 else 0\n",
    "    \n",
    "    allocation_data.append({\n",
    "        'Asset': asset,\n",
    "        'Weight (%)': round(weight * 100, 1),\n",
    "        'Amount ($)': round(amount, 2),\n",
    "        'Current Price ($)': round(current_price, 2),\n",
    "        'Units': round(units, 6)\n",
    "    })\n",
    "    \n",
    "    bar = '█' * int(weight * 40)\n",
    "    print(f\"  {asset:6} {bar:20} ${amount:>8,.2f} ({weight*100:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n  {'─'*50}\")\n",
    "print(f\"  {'TOTAL':<6} {'':20} ${INVESTMENT_AMOUNT:>8,.2f} (100.0%)\")\n",
    "\n",
    "# Display as DataFrame\n",
    "print(\"\\n\\nDetailed Allocation:\")\n",
    "allocation_df = pd.DataFrame(allocation_data)\n",
    "display(allocation_df.set_index('Asset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of allocation\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_pie = plt.cm.Set3(np.linspace(0, 1, len(clean_names)))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    best_weights * 100,\n",
    "    labels=clean_names,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors_pie,\n",
    "    explode=[0.02] * len(clean_names),\n",
    "    shadow=True,\n",
    "    startangle=90\n",
    ")\n",
    "\n",
    "# Style\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('black')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "ax.set_title(f'Optimal Portfolio Allocation\\n({best_strategy})', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add center text\n",
    "centre_circle = plt.Circle((0, 0), 0.40, fc='#1a1a2e')\n",
    "ax.add_patch(centre_circle)\n",
    "ax.text(0, 0, f'${INVESTMENT_AMOUNT:,}', ha='center', va='center', fontsize=16, fontweight='bold', color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Model Persistence - Save/Load/Delete\n",
    "\n",
    "The system supports saving trained models to disk for later use.\n",
    "\n",
    "### 9.1 Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create save directory\n",
    "SAVE_DIR = \"/app/backend/saved_models/portfolio\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Model save directory: {SAVE_DIR}\")\n",
    "print()\n",
    "\n",
    "# Save Deep Learning model\n",
    "if dl_network.is_trained and dl_network.model is not None:\n",
    "    timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"demo_deep_portfolio_{timestamp}\"\n",
    "    model_path = os.path.join(SAVE_DIR, model_name)\n",
    "    \n",
    "    # Save Keras model\n",
    "    dl_network.model.save(f\"{model_path}.keras\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'model_type': 'deep_portfolio_network',\n",
    "        'n_assets': dl_network.n_assets,\n",
    "        'lookback': dl_network.lookback,\n",
    "        'asset_names': list(price_data.keys()),\n",
    "        'created_at': timestamp\n",
    "    }\n",
    "    with open(f\"{model_path}_metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Deep Learning model saved: {model_name}\")\n",
    "\n",
    "# Save RL Agent\n",
    "if ppo_agent.is_trained:\n",
    "    timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"demo_rl_portfolio_{timestamp}\"\n",
    "    model_path = os.path.join(SAVE_DIR, model_name)\n",
    "    \n",
    "    # Save actor and critic\n",
    "    ppo_agent.actor.save(f\"{model_path}_actor.keras\")\n",
    "    ppo_agent.critic.save(f\"{model_path}_critic.keras\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'model_type': 'rl_portfolio_agent',\n",
    "        'n_assets': env.n_assets,\n",
    "        'state_dim': ppo_agent.state_dim,\n",
    "        'action_dim': ppo_agent.action_dim,\n",
    "        'training_result': rl_result,\n",
    "        'created_at': timestamp\n",
    "    }\n",
    "    with open(f\"{model_path}_metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ RL Agent model saved: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 List Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved models\n",
    "print(\"\\nSaved Portfolio Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dl_models = []\n",
    "rl_models = []\n",
    "\n",
    "if os.path.exists(SAVE_DIR):\n",
    "    for filename in os.listdir(SAVE_DIR):\n",
    "        if filename.endswith(\"_metadata.json\"):\n",
    "            with open(os.path.join(SAVE_DIR, filename), 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            model_name = filename.replace(\"_metadata.json\", \"\")\n",
    "            \n",
    "            if \"deep_portfolio\" in filename:\n",
    "                dl_models.append({'name': model_name, **metadata})\n",
    "            elif \"rl_portfolio\" in filename:\n",
    "                rl_models.append({'name': model_name, **metadata})\n",
    "\n",
    "print(f\"\\n🧠 Deep Learning Models ({len(dl_models)}):\")\n",
    "for m in dl_models:\n",
    "    print(f\"  • {m['name']}\")\n",
    "    print(f\"    Assets: {m.get('n_assets', 'N/A')} | Created: {m.get('created_at', 'N/A')}\")\n",
    "\n",
    "print(f\"\\n🤖 RL Agent Models ({len(rl_models)}):\")\n",
    "for m in rl_models:\n",
    "    print(f\"  • {m['name']}\")\n",
    "    print(f\"    Assets: {m.get('n_assets', 'N/A')} | Created: {m.get('created_at', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Conclusion & Summary\n",
    "\n",
    "### 10.1 What We Built\n",
    "\n",
    "This notebook demonstrated a complete **Multi-Input Hybrid Deep Learning System** for cryptocurrency portfolio optimization, including:\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Data Pipeline** | Fetches OHLCV data from Binance via CCXT |\n",
    "| **Feature Engineering** | Calculates 30+ technical indicators |\n",
    "| **Correlation Analysis** | Identifies diversification opportunities |\n",
    "| **4 Optimization Strategies** | MVO, Deep Learning, RL, and Hybrid |\n",
    "| **Model Persistence** | Save, load, and manage trained models |\n",
    "\n",
    "### 10.2 Key Mathematical Concepts\n",
    "\n",
    "1. **Modern Portfolio Theory (MPT)**: Maximize Sharpe Ratio = $\\frac{R_p - R_f}{\\sigma_p}$\n",
    "\n",
    "2. **Deep Learning**: Neural network with custom Sharpe loss function\n",
    "\n",
    "3. **Reinforcement Learning**: PPO agent learns optimal policy through simulation\n",
    "\n",
    "4. **Ensemble Methods**: Combine multiple strategies for robustness\n",
    "\n",
    "### 10.3 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n📊 Data:\")\n",
    "print(f\"   • Assets analyzed: {len(PORTFOLIO_ASSETS)}\")\n",
    "print(f\"   • Data period: ~{DAYS_OF_DATA} days\")\n",
    "print(f\"   • Features calculated: 30+\")\n",
    "\n",
    "print(f\"\\n🎯 Strategy Comparison:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    indicator = \"★\" if row['Strategy'] == best_strategy else \" \"\n",
    "    print(f\"   {indicator} {row['Strategy']}: Sharpe={row['Sharpe Ratio']:.3f}, Return={row['Expected Return (%)']:.1f}%\")\n",
    "\n",
    "print(f\"\\n💰 Recommended Allocation (${INVESTMENT_AMOUNT:,}):\")\n",
    "for asset, weight in zip(clean_names, best_weights):\n",
    "    if weight > 0.01:\n",
    "        print(f\"   • {asset}: ${INVESTMENT_AMOUNT * weight:,.2f} ({weight*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n✅ Models Saved: {len(dl_models)} DL + {len(rl_models)} RL\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"END OF DEMONSTRATION\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Future Enhancements\n",
    "\n",
    "1. **Real-time Trading Integration**: Connect to exchange APIs for live trading\n",
    "2. **Sentiment Analysis**: Incorporate news and social media sentiment\n",
    "3. **On-Chain Metrics**: Add blockchain-specific features (whale movements, exchange flows)\n",
    "4. **Rebalancing Alerts**: Notify when optimal allocation changes significantly\n",
    "5. **More RL Algorithms**: Implement SAC, TD3, and other advanced agents\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for reviewing this demonstration!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
